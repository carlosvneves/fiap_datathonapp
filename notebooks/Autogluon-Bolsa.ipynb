{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "\n",
    "# import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# import train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nome</th>\n",
       "      <th>ida</th>\n",
       "      <th>diff_fase</th>\n",
       "      <th>ponto_virada_encoded</th>\n",
       "      <th>anos_pm</th>\n",
       "      <th>bolsista_encoded</th>\n",
       "      <th>ipv</th>\n",
       "      <th>corraca</th>\n",
       "      <th>ponto_virada</th>\n",
       "      <th>ian</th>\n",
       "      <th>...</th>\n",
       "      <th>ips</th>\n",
       "      <th>ieg</th>\n",
       "      <th>ipp</th>\n",
       "      <th>idade</th>\n",
       "      <th>sexo_encoded</th>\n",
       "      <th>fase</th>\n",
       "      <th>inde</th>\n",
       "      <th>sexo</th>\n",
       "      <th>na_fase</th>\n",
       "      <th>ano</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALUNO-1</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.750000</td>\n",
       "      <td>R</td>\n",
       "      <td>Não</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.500</td>\n",
       "      <td>8.7</td>\n",
       "      <td>5.9375</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>7.883752</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALUNO-3</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.111113</td>\n",
       "      <td>B</td>\n",
       "      <td>Não</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.500</td>\n",
       "      <td>8.9</td>\n",
       "      <td>8.1250</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.856390</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALUNO-4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.750000</td>\n",
       "      <td>R</td>\n",
       "      <td>Não</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.875</td>\n",
       "      <td>4.1</td>\n",
       "      <td>7.1875</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.076252</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALUNO-5</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.166665</td>\n",
       "      <td>R</td>\n",
       "      <td>Não</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.500</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.4375</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>8.077085</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ALUNO-8</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.944450</td>\n",
       "      <td>R</td>\n",
       "      <td>Sim</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.375</td>\n",
       "      <td>9.9</td>\n",
       "      <td>8.7500</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>8.381391</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      nome       ida  diff_fase  ponto_virada_encoded  anos_pm  \\\n",
       "0  ALUNO-1  7.000000        0.0                     0      2.0   \n",
       "1  ALUNO-3  5.500000        0.0                     0      2.0   \n",
       "2  ALUNO-4  0.000000       -1.0                     0      2.0   \n",
       "3  ALUNO-5  7.500000        0.0                     0      1.0   \n",
       "4  ALUNO-8  7.333333        0.0                     1      3.0   \n",
       "\n",
       "   bolsista_encoded       ipv corraca ponto_virada   ian  ...    ips  ieg  \\\n",
       "0                 0  7.750000       R          Não  10.0  ...  7.500  8.7   \n",
       "1                 0  8.111113       B          Não  10.0  ...  7.500  8.9   \n",
       "2                 0  7.750000       R          Não   5.0  ...  6.875  4.1   \n",
       "3                 0  8.166665       R          Não  10.0  ...  7.500  8.0   \n",
       "4                 1  8.944450       R          Sim  10.0  ...  4.375  9.9   \n",
       "\n",
       "      ipp  idade  sexo_encoded  fase      inde  sexo  na_fase   ano  \n",
       "0  5.9375   11.0           1.0     2  7.883752     F        1  2020  \n",
       "1  8.1250   12.0           1.0     3  7.856390     F        1  2020  \n",
       "2  7.1875   10.0           0.0     1  5.076252     M        0  2020  \n",
       "3  8.4375   10.0           0.0     2  8.077085     M        1  2020  \n",
       "4  8.7500   14.0           1.0     4  8.381391     F        1  2020  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/df_pooled_common.csv\")\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ida</th>\n",
       "      <th>diff_fase</th>\n",
       "      <th>ponto_virada_encoded</th>\n",
       "      <th>anos_pm</th>\n",
       "      <th>ipv</th>\n",
       "      <th>corraca</th>\n",
       "      <th>ponto_virada</th>\n",
       "      <th>ian</th>\n",
       "      <th>pedra</th>\n",
       "      <th>iaa</th>\n",
       "      <th>...</th>\n",
       "      <th>ieg</th>\n",
       "      <th>ipp</th>\n",
       "      <th>idade</th>\n",
       "      <th>sexo_encoded</th>\n",
       "      <th>fase</th>\n",
       "      <th>inde</th>\n",
       "      <th>sexo</th>\n",
       "      <th>na_fase</th>\n",
       "      <th>ano</th>\n",
       "      <th>bolsista</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.750000</td>\n",
       "      <td>R</td>\n",
       "      <td>Não</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Ametista</td>\n",
       "      <td>8.50002</td>\n",
       "      <td>...</td>\n",
       "      <td>8.7</td>\n",
       "      <td>5.9375</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>7.883752</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>t0</td>\n",
       "      <td>não</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.111113</td>\n",
       "      <td>B</td>\n",
       "      <td>Não</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Ametista</td>\n",
       "      <td>7.91667</td>\n",
       "      <td>...</td>\n",
       "      <td>8.9</td>\n",
       "      <td>8.1250</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.856390</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>t0</td>\n",
       "      <td>não</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.750000</td>\n",
       "      <td>R</td>\n",
       "      <td>Não</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Quartzo</td>\n",
       "      <td>8.00002</td>\n",
       "      <td>...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>7.1875</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.076252</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>t0</td>\n",
       "      <td>não</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.166665</td>\n",
       "      <td>R</td>\n",
       "      <td>Não</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Ametista</td>\n",
       "      <td>7.50002</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.4375</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>8.077085</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>t0</td>\n",
       "      <td>não</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.944450</td>\n",
       "      <td>R</td>\n",
       "      <td>Sim</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Ametista</td>\n",
       "      <td>8.33334</td>\n",
       "      <td>...</td>\n",
       "      <td>9.9</td>\n",
       "      <td>8.7500</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>8.381391</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>t0</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ida  diff_fase  ponto_virada_encoded  anos_pm       ipv corraca  \\\n",
       "0  7.000000        0.0                     0      2.0  7.750000       R   \n",
       "1  5.500000        0.0                     0      2.0  8.111113       B   \n",
       "2  0.000000       -1.0                     0      2.0  7.750000       R   \n",
       "3  7.500000        0.0                     0      1.0  8.166665       R   \n",
       "4  7.333333        0.0                     1      3.0  8.944450       R   \n",
       "\n",
       "  ponto_virada   ian     pedra      iaa  ...  ieg     ipp  idade  \\\n",
       "0          Não  10.0  Ametista  8.50002  ...  8.7  5.9375   11.0   \n",
       "1          Não  10.0  Ametista  7.91667  ...  8.9  8.1250   12.0   \n",
       "2          Não   5.0   Quartzo  8.00002  ...  4.1  7.1875   10.0   \n",
       "3          Não  10.0  Ametista  7.50002  ...  8.0  8.4375   10.0   \n",
       "4          Sim  10.0  Ametista  8.33334  ...  9.9  8.7500   14.0   \n",
       "\n",
       "   sexo_encoded  fase      inde  sexo na_fase  ano bolsista  \n",
       "0           1.0     2  7.883752     F       1   t0      não  \n",
       "1           1.0     3  7.856390     F       1   t0      não  \n",
       "2           0.0     1  5.076252     M       0   t0      não  \n",
       "3           0.0     2  8.077085     M       1   t0      não  \n",
       "4           1.0     4  8.381391     F       1   t0      sim  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(columns=[\"pedra_encoded\", \"nome\"])\n",
    "\n",
    "# transforma bolsista em categoria sim/não\n",
    "data[\"bolsista\"] = (\n",
    "    data[\"bolsista_encoded\"]\n",
    "    .apply(lambda x: \"sim\" if x == 1 else \"não\")\n",
    "    .astype(\"category\")\n",
    ")\n",
    "\n",
    "data.drop(columns=[\"bolsista_encoded\"], inplace=True)\n",
    "\n",
    "# transforma pedra em categoria\n",
    "data[\"pedra\"] = data[\"pedra\"].astype(\"category\")\n",
    "\n",
    "# maps ano to t,t+1,t+2\n",
    "data[\"ano\"] = data[\"ano\"].apply(\n",
    "    lambda x: \"t0\" if x == 2020 else (\"t1\" if x == 2021 else \"t2\")\n",
    ")\n",
    "data[\"ano\"] = data[\"ano\"].astype(\"category\")\n",
    "\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionar as variáveis preditoras e a variável alvo\n",
    "# no lugar de eliminar o ano, será que daria para usar uma espécie de nota no ano t, nota no ano t+1, nota em t + 2?\n",
    "X = data.drop(columns=[\"inde\", \"bolsista\"])\n",
    "\n",
    "X = X[[\"anos_pm\", \"fase\", \"ida\", \"ipv\", \"ieg\", \"idade\", \"ipp\", \"na_fase\", \"sexo\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, data[\"bolsista\"], test_size=0.25, random_state=41, shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.concat([X_train, y_train], axis=1)\n",
    "test_data = pd.concat([X_test, y_test], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of class variable: \n",
      " count     1688\n",
      "unique       2\n",
      "top        não\n",
      "freq      1430\n",
      "Name: bolsista, dtype: object\n"
     ]
    }
   ],
   "source": [
    "label = \"bolsista\"\n",
    "print(\"Summary of class variable: \\n\", train_data[label].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           anos_pm         fase          ida          ipv          ieg  \\\n",
      "count  1688.000000  1688.000000  1688.000000  1688.000000  1688.000000   \n",
      "mean      1.558649     2.305095     5.967858     7.370089     7.570527   \n",
      "std       1.513072     1.853220     2.389013     1.333416     2.097586   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "25%       0.000000     1.000000     4.600000     6.800000     6.400000   \n",
      "50%       1.000000     2.000000     6.333333     7.500000     8.200000   \n",
      "75%       3.000000     3.000000     7.666667     8.200000     9.200000   \n",
      "max       6.000000     7.000000    10.000000    10.000010    10.000000   \n",
      "\n",
      "             idade          ipp      na_fase  \n",
      "count  1686.000000  1688.000000  1688.000000  \n",
      "mean     12.283511     7.012319     0.357820  \n",
      "std       2.629718     1.388205     0.479501  \n",
      "min       7.000000     0.000000     0.000000  \n",
      "25%      10.000000     6.250000     0.000000  \n",
      "50%      12.000000     7.343750     0.000000  \n",
      "75%      14.000000     7.968750     1.000000  \n",
      "max      20.000000    10.000000     1.000000  \n",
      "count     1688\n",
      "unique       2\n",
      "top        não\n",
      "freq      1430\n",
      "Name: bolsista, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X_train.describe())\n",
    "print(y_train.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"agModels-predictBolsista\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.11.9\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Fri Mar 29 23:14:13 UTC 2024\n",
      "CPU Count:          16\n",
      "Memory Avail:       2.50 GB / 15.49 GB (16.1%)\n",
      "Disk Space Avail:   914.22 GB / 1006.85 GB (90.8%)\n",
      "===================================================\n",
      "Presets specified: ['good_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Note: `save_bag_folds=False`! This will greatly reduce peak disk usage during fit (by ~8x), but runs the risk of an out-of-memory error during model refit if memory is small relative to the data size.\n",
      "\tYou can avoid this risk by setting `save_bag_folds=True`.\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 900s of the 3600s of remaining time (25%).\n",
      "\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n",
      "2024-09-15 22:49:16,438\tINFO worker.py:1743 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8267 \u001b[39m\u001b[22m\n",
      "\t\tContext path: \"agModels-predictBolsista/ds_sub_fit/sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Running DyStack sub-fit ...\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Beginning AutoGluon training ... Time limit = 888s\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m AutoGluon will save models to \"agModels-predictBolsista/ds_sub_fit/sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Train Data Rows:    1500\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Train Data Columns: 9\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Label Column:       bolsista\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Problem Type:       binary\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Preprocessing data ...\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Selected class <--> label mapping:  class 1 = sim, class 0 = não\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (sim) vs negative (não) class.\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Using Feature Generators to preprocess the data ...\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \tAvailable Memory:                    1906.07 MB\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \tTrain Data (Original)  Memory Usage: 0.17 MB (0.0% of available memory)\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \tStage 1 Generators:\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \tStage 2 Generators:\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \tStage 3 Generators:\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t\tFitting CategoryFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \tStage 4 Generators:\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \tStage 5 Generators:\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t\t('float', [])  : 6 | ['anos_pm', 'ida', 'ipv', 'ieg', 'idade', ...]\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t\t('int', [])    : 2 | ['fase', 'na_fase']\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t\t('object', []) : 1 | ['sexo']\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t\t('category', [])  : 1 | ['sexo']\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t\t('float', [])     : 6 | ['anos_pm', 'ida', 'ipv', 'ieg', 'idade', ...]\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t\t('int', [])       : 1 | ['fase']\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t\t('int', ['bool']) : 1 | ['na_fase']\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t0.1s = Fit runtime\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t9 features in original data used to generate 9 features in processed data.\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \tTrain Data (Processed) Memory Usage: 0.08 MB (0.0% of available memory)\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Data preprocessing and feature engineering runtime = 0.15s ...\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m User-specified model hyperparameters to be fit:\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m {\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t'NN_TORCH': {},\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t'CAT': {},\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t'XGB': {},\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t'FASTAI': {},\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t'RF': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t'XT': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m }\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Fitting 11 L1 models ...\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 591.88s of the 888.05s of remaining time.\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.12%)\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t0.9307\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t4.62s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t0.23s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Fitting model: LightGBM_BAG_L1 ... Training model for up to 579.23s of the 875.39s of remaining time.\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.23%)\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t0.9287\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t5.76s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t0.23s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 567.27s of the 863.43s of remaining time.\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t0.92\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t5.95s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t0.33s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 560.75s of the 856.91s of remaining time.\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t0.9213\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t3.57s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t0.35s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Fitting model: CatBoost_BAG_L1 ... Training model for up to 556.68s of the 852.84s of remaining time.\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=8, gpus=0, memory=0.19%)\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t0.9313\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t43.86s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t0.06s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 506.42s of the 802.58s of remaining time.\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t0.9167\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t5.27s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t0.44s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 500.43s of the 796.59s of remaining time.\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t0.9147\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t3.45s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t0.31s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 496.42s of the 792.58s of remaining time.\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=8, gpus=0, memory=0.05%)\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \tWarning: Exception caused NeuralNetFastAI_BAG_L1 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t\tTask was killed due to the node running low on memory.\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Memory on the node (IP: 172.17.251.172, ID: 208bc74ffa15fae583331bf54f4b6a65eb36bdc702f2d26d00b10ce7) where the task (task ID: acdd393430efb568776223ab5949817e4703a3afffffffff, name=_ray_fit, pid=172664, memory used=0.35GB) was running was 14.72GB / 15.49GB (0.950285), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: 54a6bbd5b4170f140637411db2da0b8125fc8f5952a53dfd4cc86e00) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 172.17.251.172`. To see the logs of the worker, use `ray logs worker-54a6bbd5b4170f140637411db2da0b8125fc8f5952a53dfd4cc86e00*out -ip 172.17.251.172. Top 10 memory users:\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m PID\tMEM(GB)\tCOMMAND\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m 95155\t1.73\t/home/alien-wsl/projects/datathon_app/datathonapp/.venv/bin/python -m ipykernel_launcher --f=/home/a...\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m 86301\t1.49\t/home/alien-wsl/projects/datathon_app/datathonapp/.venv/bin/python -m ipykernel_launcher --f=/home/a...\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m 38315\t1.36\t/home/alien-wsl/.vscode-server/bin/38c31bc77e0dd6ae88a4e9cc93428cc27a56ba40/node /home/alien-wsl/.vs...\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m 145027\t1.23\t/home/alien-wsl/projects/datathon_app/datathonapp/.venv/bin/python -m ipykernel_launcher --f=/home/a...\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m 38644\t0.45\t/home/alien-wsl/.vscode-server/extensions/codeium.codeium-1.14.12/dist/cee2c2c314ffa41c66be177dd11f9...\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m 172664\t0.35\tray::_ray_fit\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m 173055\t0.31\tray::_ray_fit\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m 173054\t0.31\tray::_ray_fit\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m 173053\t0.30\tray::_ray_fit\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m 173048\t0.30\tray::_ray_fit\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m   File \"/home/alien-wsl/projects/datathon_app/datathonapp/.venv/lib/python3.11/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1904, in _train_and_save\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m     model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m   File \"/home/alien-wsl/projects/datathon_app/datathonapp/.venv/lib/python3.11/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1844, in _train_single\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m   File \"/home/alien-wsl/projects/datathon_app/datathonapp/.venv/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m   File \"/home/alien-wsl/projects/datathon_app/datathonapp/.venv/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m   File \"/home/alien-wsl/projects/datathon_app/datathonapp/.venv/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 288, in _fit\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m   File \"/home/alien-wsl/projects/datathon_app/datathonapp/.venv/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 714, in _fit_folds\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m   File \"/home/alien-wsl/projects/datathon_app/datathonapp/.venv/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 668, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m   File \"/home/alien-wsl/projects/datathon_app/datathonapp/.venv/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 610, in _run_parallel\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m   File \"/home/alien-wsl/projects/datathon_app/datathonapp/.venv/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 572, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m   File \"/home/alien-wsl/projects/datathon_app/datathonapp/.venv/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m                                                                                                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m   File \"/home/alien-wsl/projects/datathon_app/datathonapp/.venv/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m            ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m   File \"/home/alien-wsl/projects/datathon_app/datathonapp/.venv/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m   File \"/home/alien-wsl/projects/datathon_app/datathonapp/.venv/lib/python3.11/site-packages/ray/_private/worker.py\", line 2667, in get\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m   File \"/home/alien-wsl/projects/datathon_app/datathonapp/.venv/lib/python3.11/site-packages/ray/_private/worker.py\", line 866, in get_objects\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m     raise value\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m ray.exceptions.OutOfMemoryError: Task was killed due to the node running low on memory.\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Memory on the node (IP: 172.17.251.172, ID: 208bc74ffa15fae583331bf54f4b6a65eb36bdc702f2d26d00b10ce7) where the task (task ID: acdd393430efb568776223ab5949817e4703a3afffffffff, name=_ray_fit, pid=172664, memory used=0.35GB) was running was 14.72GB / 15.49GB (0.950285), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: 54a6bbd5b4170f140637411db2da0b8125fc8f5952a53dfd4cc86e00) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 172.17.251.172`. To see the logs of the worker, use `ray logs worker-54a6bbd5b4170f140637411db2da0b8125fc8f5952a53dfd4cc86e00*out -ip 172.17.251.172. Top 10 memory users:\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m PID\tMEM(GB)\tCOMMAND\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m 95155\t1.73\t/home/alien-wsl/projects/datathon_app/datathonapp/.venv/bin/python -m ipykernel_launcher --f=/home/a...\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m 86301\t1.49\t/home/alien-wsl/projects/datathon_app/datathonapp/.venv/bin/python -m ipykernel_launcher --f=/home/a...\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m 38315\t1.36\t/home/alien-wsl/.vscode-server/bin/38c31bc77e0dd6ae88a4e9cc93428cc27a56ba40/node /home/alien-wsl/.vs...\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m 145027\t1.23\t/home/alien-wsl/projects/datathon_app/datathonapp/.venv/bin/python -m ipykernel_launcher --f=/home/a...\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m 38644\t0.45\t/home/alien-wsl/.vscode-server/extensions/codeium.codeium-1.14.12/dist/cee2c2c314ffa41c66be177dd11f9...\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m 172664\t0.35\tray::_ray_fit\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m 173055\t0.31\tray::_ray_fit\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m 173054\t0.31\tray::_ray_fit\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m 173053\t0.30\tray::_ray_fit\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m 173048\t0.30\tray::_ray_fit\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Fitting model: XGBoost_BAG_L1 ... Training model for up to 147.78s of the 443.94s of remaining time.\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=8, gpus=0, memory=0.30%)\n",
      "\u001b[33m(raylet)\u001b[0m [2024-09-15 22:57:16,371 E 168537 168537] (raylet) node_manager.cc:2967: 5 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 208bc74ffa15fae583331bf54f4b6a65eb36bdc702f2d26d00b10ce7, IP: 172.17.251.172) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.17.251.172`\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t0.912\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t138.72s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t1.12s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 2.18s of the 298.34s of remaining time.\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=8, gpus=0, memory=0.05%)\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \tWarning: Exception caused NeuralNetTorch_BAG_L1 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t\tTask was killed due to the node running low on memory.\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Memory on the node (IP: 172.17.251.172, ID: 208bc74ffa15fae583331bf54f4b6a65eb36bdc702f2d26d00b10ce7) where the task (task ID: 583a3e2c6b26b231a62da85b0aa480b3bf3ead07ffffffff, name=_ray_fit, pid=177316, memory used=0.10GB) was running was 14.72GB / 15.49GB (0.950696), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: 15055644bd3fbe7eb712da634cad2ed73ebff7ecfef67dafc110ce55) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 172.17.251.172`. To see the logs of the worker, use `ray logs worker-15055644bd3fbe7eb712da634cad2ed73ebff7ecfef67dafc110ce55*out -ip 172.17.251.172. Top 10 memory users:\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m PID\tMEM(GB)\tCOMMAND\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m 95155\t1.73\t/home/alien-wsl/projects/datathon_app/datathonapp/.venv/bin/python -m ipykernel_launcher --f=/home/a...\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m 38315\t1.40\t/home/alien-wsl/.vscode-server/bin/38c31bc77e0dd6ae88a4e9cc93428cc27a56ba40/node /home/alien-wsl/.vs...\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m 86301\t1.32\t/home/alien-wsl/projects/datathon_app/datathonapp/.venv/bin/python -m ipykernel_launcher --f=/home/a...\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m 145027\t1.22\t/home/alien-wsl/projects/datathon_app/datathonapp/.venv/bin/python -m ipykernel_launcher --f=/home/a...\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m 38644\t0.47\t/home/alien-wsl/.vscode-server/extensions/codeium.codeium-1.14.12/dist/cee2c2c314ffa41c66be177dd11f9...\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m 174955\t0.36\tray::IDLE\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m 174954\t0.36\tray::IDLE\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m 88636\t0.29\t/home/alien-wsl/projects/datathon_app/datathonapp/.venv/bin/python /home/alien-wsl/projects/datathon...\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m 103108\t0.29\t/home/alien-wsl/projects/datathon_app/datathonapp/.venv/bin/python /home/alien-wsl/projects/datathon...\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m 36643\t0.29\t/home/alien-wsl/.vscode-server/bin/38c31bc77e0dd6ae88a4e9cc93428cc27a56ba40/node --dns-result-order=...\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m   File \"/home/alien-wsl/projects/datathon_app/datathonapp/.venv/lib/python3.11/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1904, in _train_and_save\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m     model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m   File \"/home/alien-wsl/projects/datathon_app/datathonapp/.venv/lib/python3.11/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1844, in _train_single\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m   File \"/home/alien-wsl/projects/datathon_app/datathonapp/.venv/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m   File \"/home/alien-wsl/projects/datathon_app/datathonapp/.venv/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m   File \"/home/alien-wsl/projects/datathon_app/datathonapp/.venv/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 288, in _fit\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m   File \"/home/alien-wsl/projects/datathon_app/datathonapp/.venv/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 714, in _fit_folds\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m   File \"/home/alien-wsl/projects/datathon_app/datathonapp/.venv/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 668, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m   File \"/home/alien-wsl/projects/datathon_app/datathonapp/.venv/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 610, in _run_parallel\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m   File \"/home/alien-wsl/projects/datathon_app/datathonapp/.venv/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 572, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m   File \"/home/alien-wsl/projects/datathon_app/datathonapp/.venv/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m                                                                                                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m   File \"/home/alien-wsl/projects/datathon_app/datathonapp/.venv/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m            ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m   File \"/home/alien-wsl/projects/datathon_app/datathonapp/.venv/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m   File \"/home/alien-wsl/projects/datathon_app/datathonapp/.venv/lib/python3.11/site-packages/ray/_private/worker.py\", line 2667, in get\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m   File \"/home/alien-wsl/projects/datathon_app/datathonapp/.venv/lib/python3.11/site-packages/ray/_private/worker.py\", line 866, in get_objects\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m     raise value\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m ray.exceptions.OutOfMemoryError: Task was killed due to the node running low on memory.\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Memory on the node (IP: 172.17.251.172, ID: 208bc74ffa15fae583331bf54f4b6a65eb36bdc702f2d26d00b10ce7) where the task (task ID: 583a3e2c6b26b231a62da85b0aa480b3bf3ead07ffffffff, name=_ray_fit, pid=177316, memory used=0.10GB) was running was 14.72GB / 15.49GB (0.950696), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: 15055644bd3fbe7eb712da634cad2ed73ebff7ecfef67dafc110ce55) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 172.17.251.172`. To see the logs of the worker, use `ray logs worker-15055644bd3fbe7eb712da634cad2ed73ebff7ecfef67dafc110ce55*out -ip 172.17.251.172. Top 10 memory users:\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m PID\tMEM(GB)\tCOMMAND\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m 95155\t1.73\t/home/alien-wsl/projects/datathon_app/datathonapp/.venv/bin/python -m ipykernel_launcher --f=/home/a...\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m 38315\t1.40\t/home/alien-wsl/.vscode-server/bin/38c31bc77e0dd6ae88a4e9cc93428cc27a56ba40/node /home/alien-wsl/.vs...\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m 86301\t1.32\t/home/alien-wsl/projects/datathon_app/datathonapp/.venv/bin/python -m ipykernel_launcher --f=/home/a...\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m 145027\t1.22\t/home/alien-wsl/projects/datathon_app/datathonapp/.venv/bin/python -m ipykernel_launcher --f=/home/a...\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m 38644\t0.47\t/home/alien-wsl/.vscode-server/extensions/codeium.codeium-1.14.12/dist/cee2c2c314ffa41c66be177dd11f9...\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m 174955\t0.36\tray::IDLE\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m 174954\t0.36\tray::IDLE\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m 88636\t0.29\t/home/alien-wsl/projects/datathon_app/datathonapp/.venv/bin/python /home/alien-wsl/projects/datathon...\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m 103108\t0.29\t/home/alien-wsl/projects/datathon_app/datathonapp/.venv/bin/python /home/alien-wsl/projects/datathon...\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m 36643\t0.29\t/home/alien-wsl/.vscode-server/bin/38c31bc77e0dd6ae88a4e9cc93428cc27a56ba40/node --dns-result-order=...\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 293.28s of remaining time.\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \tEnsemble Weights: {'CatBoost_BAG_L1': 1.0}\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t0.9313\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t0.52s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t0.0s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Fitting 11 L2 models ...\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 292.63s of the 292.59s of remaining time.\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.27%)\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t0.932\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t13.26s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t0.13s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Fitting model: LightGBM_BAG_L2 ... Training model for up to 270.96s of the 270.93s of remaining time.\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.26%)\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t0.9313\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t13.06s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 252.0s of the 251.96s of remaining time.\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t0.9253\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t4.66s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t0.43s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 246.77s of the 246.73s of remaining time.\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t0.9267\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t4.69s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t0.35s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Fitting model: CatBoost_BAG_L2 ... Training model for up to 241.59s of the 241.55s of remaining time.\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=8, gpus=0, memory=0.27%)\n",
      "\u001b[33m(raylet)\u001b[0m [2024-09-15 23:00:16,378 E 168537 168537] (raylet) node_manager.cc:2967: 6 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 208bc74ffa15fae583331bf54f4b6a65eb36bdc702f2d26d00b10ce7, IP: 172.17.251.172) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.17.251.172`\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t0.93\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t28.16s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t0.04s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 209.45s of the 209.41s of remaining time.\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t0.9247\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t1.73s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t0.18s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Fitting model: ExtraTreesEntr_BAG_L2 ... Training model for up to 207.46s of the 207.43s of remaining time.\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t0.9227\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t2.47s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t0.34s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 204.52s of the 204.49s of remaining time.\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=8, gpus=0, memory=0.05%)\n",
      "\u001b[33m(raylet)\u001b[0m [2024-09-15 23:01:16,380 E 168537 168537] (raylet) node_manager.cc:2967: 2 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 208bc74ffa15fae583331bf54f4b6a65eb36bdc702f2d26d00b10ce7, IP: 172.17.251.172) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.17.251.172`\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-09-15 23:02:16,382 E 168537 168537] (raylet) node_manager.cc:2967: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 208bc74ffa15fae583331bf54f4b6a65eb36bdc702f2d26d00b10ce7, IP: 172.17.251.172) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.17.251.172`\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t0.9233\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t189.13s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t1.48s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Fitting model: XGBoost_BAG_L2 ... Training model for up to 10.07s of the 10.04s of remaining time.\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=8, gpus=0, memory=0.20%)\n",
      "\u001b[33m(raylet)\u001b[0m [2024-09-15 23:04:16,400 E 168537 168537] (raylet) node_manager.cc:2967: 3 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 208bc74ffa15fae583331bf54f4b6a65eb36bdc702f2d26d00b10ce7, IP: 172.17.251.172) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.17.251.172`\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t0.8773\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t30.89s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t0.67s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the -24.46s of remaining time.\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \tEnsemble Weights: {'LightGBMXT_BAG_L2': 1.0}\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t0.932\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t0.55s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t0.0s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m AutoGluon training complete, total runtime = 913.26s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 95.7 rows/s (188 batch size)\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Fitting 1 L1 models ...\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t6.11s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Fitting 1 L1 models ...\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t26.25s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Fitting model: RandomForestGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t5.95s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t0.33s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Fitting model: RandomForestEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t3.57s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t0.35s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Fitting 1 L1 models ...\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Fitting model: CatBoost_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t1.59s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Fitting model: ExtraTreesGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t5.27s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t0.44s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Fitting model: ExtraTreesEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t3.45s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t0.31s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Fitting 1 L1 models ...\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Fitting model: XGBoost_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t2.42s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \tEnsemble Weights: {'CatBoost_BAG_L1': 1.0}\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t0.52s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Fitting 1 L2 models ...\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t1.9s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Fitting 1 L2 models ...\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Fitting model: LightGBM_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t2.95s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Fitting model: RandomForestGini_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t4.66s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t0.43s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Fitting model: RandomForestEntr_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t4.69s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t0.35s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Fitting 1 L2 models ...\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Fitting model: CatBoost_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t0.23s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Fitting model: ExtraTreesGini_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t1.73s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t0.18s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Fitting model: ExtraTreesEntr_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t2.47s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t0.34s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Fitting 1 L2 models ...\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \tStopping at the best epoch learned earlier - 9.\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t8.45s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Fitting 1 L2 models ...\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Fitting model: XGBoost_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t0.67s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \tEnsemble Weights: {'LightGBMXT_BAG_L2': 1.0}\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m \t0.55s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Updated best model to \"LightGBMXT_BAG_L2_FULL\" (Previously \"WeightedEnsemble_L3\"). AutoGluon will default to using \"LightGBMXT_BAG_L2_FULL\" for predict() and predict_proba().\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Refit complete, total runtime = 57.6s ... Best model: \"LightGBMXT_BAG_L2_FULL\"\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels-predictBolsista/ds_sub_fit/sub_fit_ho\")\n",
      "\u001b[36m(_dystack pid=168628)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                           model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0     ExtraTreesGini_BAG_L1_FULL       0.941489   0.916667    accuracy        0.208945       0.444416   5.274801                 0.208945                0.444416           5.274801            1       True          6\n",
      "1     ExtraTreesEntr_BAG_L1_FULL       0.941489   0.914667    accuracy        0.264748       0.308185   3.446166                 0.264748                0.308185           3.446166            1       True          7\n",
      "2           CatBoost_BAG_L1_FULL       0.936170   0.931333    accuracy        0.008669            NaN   1.585372                 0.008669                     NaN           1.585372            1       True          5\n",
      "3       WeightedEnsemble_L2_FULL       0.936170   0.931333    accuracy        0.019316            NaN   2.102646                 0.010648                     NaN           0.517274            2       True          9\n",
      "4           LightGBM_BAG_L2_FULL       0.936170   0.931333    accuracy        1.375560            NaN  57.553877                 0.088784                     NaN           2.945382            2       True         11\n",
      "5    NeuralNetFastAI_BAG_L2_FULL       0.936170   0.923333    accuracy        1.427908            NaN  63.054713                 0.141132                     NaN           8.446218            2       True         17\n",
      "6   RandomForestGini_BAG_L2_FULL       0.936170   0.925333    accuracy        1.554626            NaN  59.269964                 0.267850                0.431920           4.661469            2       True         12\n",
      "7            XGBoost_BAG_L1_FULL       0.930851   0.912000    accuracy        0.160096            NaN   2.421452                 0.160096                     NaN           2.421452            1       True          8\n",
      "8   RandomForestEntr_BAG_L1_FULL       0.930851   0.921333    accuracy        0.202163       0.353177   3.573956                 0.202163                0.353177           3.573956            1       True          4\n",
      "9   RandomForestGini_BAG_L1_FULL       0.930851   0.920000    accuracy        0.280714       0.326597   5.953220                 0.280714                0.326597           5.953220            1       True          3\n",
      "10          CatBoost_BAG_L2_FULL       0.930851   0.930000    accuracy        1.296373            NaN  54.834259                 0.009597                     NaN           0.225765            2       True         14\n",
      "11  RandomForestEntr_BAG_L2_FULL       0.930851   0.926667    accuracy        1.452285            NaN  59.302224                 0.165509                0.348129           4.693730            2       True         13\n",
      "12    ExtraTreesGini_BAG_L2_FULL       0.930851   0.924667    accuracy        1.475265            NaN  56.337725                 0.188488                0.182279           1.729230            2       True         15\n",
      "13    ExtraTreesEntr_BAG_L2_FULL       0.930851   0.922667    accuracy        1.491479            NaN  57.078867                 0.204703                0.343961           2.470372            2       True         16\n",
      "14        LightGBMXT_BAG_L2_FULL       0.925532   0.932000    accuracy        1.356361            NaN  56.504956                 0.069585                     NaN           1.896461            2       True         10\n",
      "15      WeightedEnsemble_L3_FULL       0.925532   0.932000    accuracy        1.359629            NaN  57.050860                 0.003268                     NaN           0.545905            3       True         19\n",
      "16          LightGBM_BAG_L1_FULL       0.914894   0.928667    accuracy        0.070678            NaN  26.247068                 0.070678                     NaN          26.247068            1       True          2\n",
      "17        LightGBMXT_BAG_L1_FULL       0.909574   0.930667    accuracy        0.090764            NaN   6.106460                 0.090764                     NaN           6.106460            1       True          1\n",
      "18           XGBoost_BAG_L2_FULL       0.845745   0.877333    accuracy        1.449544            NaN  55.274956                 0.162768                     NaN           0.666462            2       True         18\n",
      "\t0\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: True)\n",
      "\t993s\t = DyStack   runtime |\t2607s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=0.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=0)`\n",
      "Beginning AutoGluon training ... Time limit = 2607s\n",
      "AutoGluon will save models to \"agModels-predictBolsista\"\n",
      "Train Data Rows:    1688\n",
      "Train Data Columns: 9\n",
      "Label Column:       bolsista\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = sim, class 0 = não\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (sim) vs negative (não) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2709.88 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.20 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 6 | ['anos_pm', 'ida', 'ipv', 'ieg', 'idade', ...]\n",
      "\t\t('int', [])    : 2 | ['fase', 'na_fase']\n",
      "\t\t('object', []) : 1 | ['sexo']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 1 | ['sexo']\n",
      "\t\t('float', [])     : 6 | ['anos_pm', 'ida', 'ipv', 'ieg', 'idade', ...]\n",
      "\t\t('int', [])       : 1 | ['fase']\n",
      "\t\t('int', ['bool']) : 1 | ['na_fase']\n",
      "\t0.5s = Fit runtime\n",
      "\t9 features in original data used to generate 9 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.09 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.76s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 2605.78s of the 2605.71s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.09%)\n",
      "\t0.9307\t = Validation score   (accuracy)\n",
      "\t2.28s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 2597.66s of the 2597.6s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.11%)\n",
      "\t0.9307\t = Validation score   (accuracy)\n",
      "\t3.98s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 2587.23s of the 2587.17s of remaining time.\n",
      "\t0.9224\t = Validation score   (accuracy)\n",
      "\t2.23s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 2584.6s of the 2584.54s of remaining time.\n",
      "\t0.923\t = Validation score   (accuracy)\n",
      "\t2.65s\t = Training   runtime\n",
      "\t0.29s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 2581.59s of the 2581.53s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=8, gpus=0, memory=0.10%)\n",
      "\t0.9301\t = Validation score   (accuracy)\n",
      "\t25.29s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 2551.95s of the 2551.89s of remaining time.\n",
      "\t0.9182\t = Validation score   (accuracy)\n",
      "\t2.63s\t = Training   runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 2548.98s of the 2548.91s of remaining time.\n",
      "\t0.9171\t = Validation score   (accuracy)\n",
      "\t2.18s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 2546.33s of the 2546.27s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=8, gpus=0, memory=0.07%)\n",
      "\t0.9313\t = Validation score   (accuracy)\n",
      "\t322.8s\t = Training   runtime\n",
      "\t1.06s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 2219.2s of the 2219.14s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=8, gpus=0, memory=0.10%)\n",
      "\t0.9277\t = Validation score   (accuracy)\n",
      "\t84.94s\t = Training   runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 2131.32s of the 2131.26s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=8, gpus=0, memory=0.02%)\n",
      "\t0.9313\t = Validation score   (accuracy)\n",
      "\t89.65s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 2038.56s of the 2038.5s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.16%)\n",
      "\t0.9271\t = Validation score   (accuracy)\n",
      "\t2.76s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 2031.84s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 1.0}\n",
      "\t0.9313\t = Validation score   (accuracy)\n",
      "\t0.31s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 575.08s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 199.6 rows/s (211 batch size)\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\t3.18s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\t0.65s\t = Training   runtime\n",
      "Fitting model: RandomForestGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t2.23s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t2.65s\t = Training   runtime\n",
      "\t0.29s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: CatBoost_BAG_L1_FULL ...\n",
      "\t0.1s\t = Training   runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t2.63s\t = Training   runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t2.18s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 14.\n",
      "\t1.64s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: XGBoost_BAG_L1_FULL ...\n",
      "\t0.22s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetTorch_BAG_L1_FULL ...\n",
      "\t2.02s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMLarge_BAG_L1_FULL ...\n",
      "\t0.82s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 1.0}\n",
      "\t0.31s\t = Training   runtime\n",
      "Updated best model to \"NeuralNetTorch_BAG_L1_FULL\" (Previously \"WeightedEnsemble_L2\"). AutoGluon will default to using \"NeuralNetTorch_BAG_L1_FULL\" for predict() and predict_proba().\n",
      "Refit complete, total runtime = 9.15s ... Best model: \"NeuralNetTorch_BAG_L1_FULL\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels-predictBolsista\")\n"
     ]
    }
   ],
   "source": [
    "save_path = \"agModels-predictBolsista\"  # specifies folder to store trained models\n",
    "predictor = TabularPredictor(\n",
    "    label=label,\n",
    "    path=save_path,\n",
    ").fit(train_data, presets=\"good_quality\", num_gpus=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anos_pm</th>\n",
       "      <th>fase</th>\n",
       "      <th>ida</th>\n",
       "      <th>ipv</th>\n",
       "      <th>ieg</th>\n",
       "      <th>idade</th>\n",
       "      <th>ipp</th>\n",
       "      <th>na_fase</th>\n",
       "      <th>sexo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>5.916675</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.50000</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.944443</td>\n",
       "      <td>9.300000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.12500</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1815</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>5.166667</td>\n",
       "      <td>8.277780</td>\n",
       "      <td>9.136364</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.96875</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.333335</td>\n",
       "      <td>8.200000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.50000</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1363</th>\n",
       "      <td>5.0</td>\n",
       "      <td>7</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>6.70000</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      anos_pm  fase       ida       ipv        ieg  idade      ipp  na_fase  \\\n",
       "272       0.0     0  5.750000  5.916675  10.000000    8.0  2.50000        1   \n",
       "15        2.0     2  7.000000  7.944443   9.300000   12.0  8.12500        0   \n",
       "1815      0.0     3  5.166667  8.277780   9.136364   13.0  7.96875        1   \n",
       "387       2.0     2  9.000000  8.333335   8.200000   10.0  7.50000        1   \n",
       "1363      5.0     7  5.800000  5.400000   7.200000   17.0  6.70000        1   \n",
       "\n",
       "     sexo  \n",
       "272     M  \n",
       "15      F  \n",
       "1815    M  \n",
       "387     M  \n",
       "1363    M  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = test_data[label]  # values to predict\n",
    "test_data_nolab = X_test  # delete label column to prove we're not cheating\n",
    "test_data_nolab.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('category', [])  : 1 | ['sexo']\n",
      "('float', [])     : 6 | ['anos_pm', 'ida', 'ipv', 'ieg', 'idade', ...]\n",
      "('int', [])       : 1 | ['fase']\n",
      "('int', ['bool']) : 1 | ['na_fase']\n"
     ]
    }
   ],
   "source": [
    "print(predictor.feature_metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:  \n",
      " 272     não\n",
      "15      não\n",
      "1815    não\n",
      "387     não\n",
      "1363    sim\n",
      "       ... \n",
      "556     não\n",
      "491     não\n",
      "109     não\n",
      "1121    sim\n",
      "1976    não\n",
      "Name: bolsista, Length: 563, dtype: object\n"
     ]
    }
   ],
   "source": [
    "save_path = \"agModels-predictBolsista\"  # specifies folder to store trained models\n",
    "\n",
    "predictor = TabularPredictor.load(\n",
    "    save_path\n",
    ")  # unnecessary, just demonstrates how to load previously-trained predictor from file\n",
    "\n",
    "y_pred = predictor.predict(test_data_nolab)\n",
    "print(\"Predictions:  \\n\", y_pred)\n",
    "perf = predictor.evaluate_predictions(\n",
    "    y_true=y_test, y_pred=y_pred, auxiliary_metrics=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.9094138543516874, 'balanced_accuracy': 0.7847822845213241, 'mcc': 0.6188171555228905, 'f1': 0.6666666666666666, 'precision': 0.7391304347826086, 'recall': 0.6071428571428571}\n"
     ]
    }
   ],
   "source": [
    "print(perf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                           model  score_val eval_metric  pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0          NeuralNetTorch_BAG_L1   0.931280    accuracy       0.153149   89.648796                0.153149          89.648796            1      False         10\n",
      "1         NeuralNetFastAI_BAG_L1   0.931280    accuracy       1.056858  322.803923                1.056858         322.803923            1      False          8\n",
      "2            WeightedEnsemble_L2   0.931280    accuracy       1.058576  323.117744                0.001718           0.313822            2      False         12\n",
      "3              LightGBMXT_BAG_L1   0.930687    accuracy       0.101023    2.280487                0.101023           2.280487            1      False          1\n",
      "4                LightGBM_BAG_L1   0.930687    accuracy       0.177161    3.982239                0.177161           3.982239            1      False          2\n",
      "5                CatBoost_BAG_L1   0.930095    accuracy       0.034807   25.286460                0.034807          25.286460            1      False          5\n",
      "6                 XGBoost_BAG_L1   0.927725    accuracy       0.257835   84.943411                0.257835          84.943411            1      False          9\n",
      "7           LightGBMLarge_BAG_L1   0.927133    accuracy       0.060679    2.759384                0.060679           2.759384            1      False         11\n",
      "8        RandomForestEntr_BAG_L1   0.922986    accuracy       0.292041    2.649748                0.292041           2.649748            1       True          4\n",
      "9        RandomForestGini_BAG_L1   0.922393    accuracy       0.244081    2.228429                0.244081           2.228429            1       True          3\n",
      "10         ExtraTreesGini_BAG_L1   0.918246    accuracy       0.261758    2.631347                0.261758           2.631347            1       True          6\n",
      "11         ExtraTreesEntr_BAG_L1   0.917062    accuracy       0.375111    2.178683                0.375111           2.178683            1       True          7\n",
      "12  RandomForestGini_BAG_L1_FULL        NaN    accuracy       0.244081    2.228429                0.244081           2.228429            1       True         15\n",
      "13    ExtraTreesGini_BAG_L1_FULL        NaN    accuracy       0.261758    2.631347                0.261758           2.631347            1       True         18\n",
      "14  RandomForestEntr_BAG_L1_FULL        NaN    accuracy       0.292041    2.649748                0.292041           2.649748            1       True         16\n",
      "15    ExtraTreesEntr_BAG_L1_FULL        NaN    accuracy       0.375111    2.178683                0.375111           2.178683            1       True         19\n",
      "16           XGBoost_BAG_L1_FULL        NaN    accuracy            NaN    0.218163                     NaN           0.218163            1       True         21\n",
      "17      WeightedEnsemble_L2_FULL        NaN    accuracy            NaN    1.956021                     NaN           0.313822            2       True         24\n",
      "18    NeuralNetTorch_BAG_L1_FULL        NaN    accuracy            NaN    2.015996                     NaN           2.015996            1       True         22\n",
      "19   NeuralNetFastAI_BAG_L1_FULL        NaN    accuracy            NaN    1.642199                     NaN           1.642199            1       True         20\n",
      "20          LightGBM_BAG_L1_FULL        NaN    accuracy            NaN    0.645399                     NaN           0.645399            1       True         14\n",
      "21        LightGBMXT_BAG_L1_FULL        NaN    accuracy            NaN    3.182150                     NaN           3.182150            1       True         13\n",
      "22     LightGBMLarge_BAG_L1_FULL        NaN    accuracy            NaN    0.824748                     NaN           0.824748            1       True         23\n",
      "23          CatBoost_BAG_L1_FULL        NaN    accuracy            NaN    0.095915                     NaN           0.095915            1       True         17\n",
      "Number of models trained: 24\n",
      "Types of models trained:\n",
      "{'StackerEnsembleModel_LGB', 'StackerEnsembleModel_XGBoost', 'StackerEnsembleModel_NNFastAiTabular', 'StackerEnsembleModel_TabularNeuralNetTorch', 'WeightedEnsembleModel', 'StackerEnsembleModel_XT', 'StackerEnsembleModel_CatBoost', 'StackerEnsembleModel_RF'}\n",
      "Bagging used: True  (with 8 folds)\n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', [])  : 1 | ['sexo']\n",
      "('float', [])     : 6 | ['anos_pm', 'ida', 'ipv', 'ieg', 'idade', ...]\n",
      "('int', [])       : 1 | ['fase']\n",
      "('int', ['bool']) : 1 | ['na_fase']\n",
      "Plot summary of models saved to file: agModels-predictBolsistaSummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gio: file:///home/alien-wsl/projects/datathon_app/datathonapp/notebooks/agModels-predictBolsistaSummaryOfModels.html: Failed to find default application for content type ‘text/html’\n"
     ]
    }
   ],
   "source": [
    "results = predictor.fit_summary(show_plot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>stddev</th>\n",
       "      <th>p_value</th>\n",
       "      <th>n</th>\n",
       "      <th>p99_high</th>\n",
       "      <th>p99_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fase</th>\n",
       "      <td>0.084547</td>\n",
       "      <td>0.015362</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>5</td>\n",
       "      <td>0.116177</td>\n",
       "      <td>0.052917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anos_pm</th>\n",
       "      <td>0.074245</td>\n",
       "      <td>0.006925</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>5</td>\n",
       "      <td>0.088504</td>\n",
       "      <td>0.059987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ida</th>\n",
       "      <td>0.019183</td>\n",
       "      <td>0.007783</td>\n",
       "      <td>0.002644</td>\n",
       "      <td>5</td>\n",
       "      <td>0.035208</td>\n",
       "      <td>0.003158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>na_fase</th>\n",
       "      <td>0.013144</td>\n",
       "      <td>0.004089</td>\n",
       "      <td>0.000993</td>\n",
       "      <td>5</td>\n",
       "      <td>0.021563</td>\n",
       "      <td>0.004724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ieg</th>\n",
       "      <td>0.009591</td>\n",
       "      <td>0.007388</td>\n",
       "      <td>0.021991</td>\n",
       "      <td>5</td>\n",
       "      <td>0.024803</td>\n",
       "      <td>-0.005620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idade</th>\n",
       "      <td>0.008881</td>\n",
       "      <td>0.004528</td>\n",
       "      <td>0.005913</td>\n",
       "      <td>5</td>\n",
       "      <td>0.018205</td>\n",
       "      <td>-0.000443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ipp</th>\n",
       "      <td>0.008526</td>\n",
       "      <td>0.004423</td>\n",
       "      <td>0.006270</td>\n",
       "      <td>5</td>\n",
       "      <td>0.017632</td>\n",
       "      <td>-0.000581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ipv</th>\n",
       "      <td>0.005684</td>\n",
       "      <td>0.005944</td>\n",
       "      <td>0.049650</td>\n",
       "      <td>5</td>\n",
       "      <td>0.017923</td>\n",
       "      <td>-0.006556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sexo</th>\n",
       "      <td>-0.001066</td>\n",
       "      <td>0.003227</td>\n",
       "      <td>0.749415</td>\n",
       "      <td>5</td>\n",
       "      <td>0.005578</td>\n",
       "      <td>-0.007709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         importance    stddev   p_value  n  p99_high   p99_low\n",
       "fase       0.084547  0.015362  0.000125  5  0.116177  0.052917\n",
       "anos_pm    0.074245  0.006925  0.000009  5  0.088504  0.059987\n",
       "ida        0.019183  0.007783  0.002644  5  0.035208  0.003158\n",
       "na_fase    0.013144  0.004089  0.000993  5  0.021563  0.004724\n",
       "ieg        0.009591  0.007388  0.021991  5  0.024803 -0.005620\n",
       "idade      0.008881  0.004528  0.005913  5  0.018205 -0.000443\n",
       "ipp        0.008526  0.004423  0.006270  5  0.017632 -0.000581\n",
       "ipv        0.005684  0.005944  0.049650  5  0.017923 -0.006556\n",
       "sexo      -0.001066  0.003227  0.749415  5  0.005578 -0.007709"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.feature_importance(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_importance = predictor.feature_importance(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fase', 'anos_pm', 'ida', 'na_fase', 'ieg', 'idade', 'ipp', 'ipv']\n"
     ]
    }
   ],
   "source": [
    "print(features_importance[features_importance[\"importance\"] > 0].index.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfsAAAGwCAYAAACuFMx9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA9QUlEQVR4nO3de3wU5fn///cmIedsIGCyREIEUSAlgGKL2yqiRMLhi1DwZ1WKURE/YqAKVZEWOapRtKJoBGqVaEuKhyotFNGIErQEC6ER5JAaRBMhB5VCSDCn3fn9QbN2BTTLbrJk5/XsYx5m77ln5lqlXLnu+54Zi2EYhgAAQMAK8ncAAACgdZHsAQAIcCR7AAACHMkeAIAAR7IHACDAkewBAAhwJHsAAAJciL8D8IbT6dShQ4cUExMji8Xi73AAAB4yDEPHjh1TYmKigoJar/6sq6tTQ0OD1+cJDQ1VeHi4DyJqW+062R86dEhJSUn+DgMA4KWysjJ169atVc5dV1enHsnRqqhyeH0um82mAwcOtLuE366TfUxMjCTp8x3nyRrNjAQC088vTPV3CECraVKjPtB619/nraGhoUEVVQ59XnierDFnniuqjzmVPOgzNTQ0kOzbUvPQvTU6yKv/gMDZLMTSwd8hAK3nvw9sb4up2OgYi6Jjzvw6TrXf6eJ2newBAGgph+GUw4u3wTgMp++CaWMkewCAKThlyKkzz/beHOtvjH0DABDgSPYAAFNw+uB/Z+qRRx6RxWLR3Xff7WobOnSoLBaL23bHHXe4HVdaWqrRo0crMjJS8fHxuvfee9XU1OTx9RnGBwCYgsMw5DDOfCj+TI/dtm2bVqxYof79+5+0b8qUKVq4cKHrc2Rk5LfXczg0evRo2Ww2bdmyReXl5brpppvUoUMHPfzwwx7FQGUPAIAHqqur3bb6+vrT9q2pqdHEiRP13HPPqVOnTiftj4yMlM1mc21Wq9W17+2339aePXv0pz/9SQMHDtTIkSO1aNEiZWdne/yAIJI9AMAUmhfoebNJUlJSkmJjY11bVlbWaa+ZmZmp0aNHKy0t7ZT7V61apS5duqhfv36aPXu2jh8/7tpXUFCg1NRUJSQkuNrS09NVXV2t3bt3e/TdGcYHAJiCU4YcPliNX1ZW5laBh4WFnbL/6tWrtWPHDm3btu2U+2+88UYlJycrMTFRO3fu1KxZs1RcXKzXX39dklRRUeGW6CW5PldUVHgUO8keAAAPWK1Wt2R/KmVlZbrrrruUl5d32qft3X777a6fU1NT1bVrVw0bNkz79+/X+eef79OYGcYHAJiCr4bxW6KwsFBVVVW6+OKLFRISopCQEOXn52vp0qUKCQmRw3Hyc/oHDx4sSSopKZF04jn8lZWVbn2aP9tsNo++O5U9AMAU2nI1/rBhw7Rr1y63tltuuUV9+vTRrFmzFBwcfNIxRUVFkqSuXbtKkux2ux566CFVVVUpPj5ekpSXlyer1aqUlBSPYifZAwDgYzExMerXr59bW1RUlDp37qx+/fpp//79ys3N1ahRo9S5c2ft3LlTM2bM0JAhQ1y36A0fPlwpKSmaNGmSFi9erIqKCs2ZM0eZmZmnXSdwOiR7AIApOP+7eXO8r4SGhuqdd97Rk08+qdraWiUlJWnChAmaM2eOq09wcLDWrVunqVOnym63KyoqShkZGW735bcUyR4AYAoOL1fje3OsJG3atMn1c1JSkvLz83/wmOTkZK1fv96r60okewCASTgMefnWO9/F0tZYjQ8AQICjsgcAmMLZNGff1kj2AABTcMoihyxeHd9eMYwPAECAo7IHAJiC0zixeXN8e0WyBwCYgsPLYXxvjvU3hvEBAAhwVPYAAFMwc2VPsgcAmILTsMhpeLEa34tj/Y1hfAAAAhyVPQDAFBjGBwAgwDkUJIcXA9oOH8bS1kj2AABTMLycszeYswcAAGcrKnsAgCkwZw8AQIBzGEFyGF7M2bfjx+UyjA8AQICjsgcAmIJTFjm9qHGdar+lPckeAGAKZp6zZxgfAIAAR2UPADAF7xfoMYwPAMBZ7cScvRcvwmEYHwAAnK2o7AEApuD08tn4rMYHAOAsx5w9AAABzqkg095nz5w9AAABjsoeAGAKDsMihxevqfXmWH8j2QMATMHh5QI9B8P4AADgdB555BFZLBbdfffdrra6ujplZmaqc+fOio6O1oQJE1RZWel2XGlpqUaPHq3IyEjFx8fr3nvvVVNTk8fXJ9kDAEzBaQR5vZ2Jbdu2acWKFerfv79b+4wZM7R27Vq9+uqrys/P16FDhzR+/HjXfofDodGjR6uhoUFbtmzRiy++qJycHM2dO9fjGEj2AABTaB7G92bzVE1NjSZOnKjnnntOnTp1crUfPXpUzz//vJ544gldddVVGjRokFauXKktW7Zo69atkqS3335be/bs0Z/+9CcNHDhQI0eO1KJFi5Sdna2GhgaP4iDZAwDggerqaretvr7+tH0zMzM1evRopaWlubUXFhaqsbHRrb1Pnz7q3r27CgoKJEkFBQVKTU1VQkKCq096erqqq6u1e/duj2JmgR4AwBSc8m5FvfO//0xKSnJrnzdvnubPn39S/9WrV2vHjh3atm3bSfsqKioUGhqqjh07urUnJCSooqLC1ed/E33z/uZ9niDZAwBMwfuH6pw4tqysTFar1dUeFhZ2Ut+ysjLdddddysvLU3h4+Blf01cYxgcAwANWq9VtO1WyLywsVFVVlS6++GKFhIQoJCRE+fn5Wrp0qUJCQpSQkKCGhgYdOXLE7bjKykrZbDZJks1mO2l1fvPn5j4tRbIHAJhC87PxvdlaatiwYdq1a5eKiopc2yWXXKKJEye6fu7QoYM2btzoOqa4uFilpaWy2+2SJLvdrl27dqmqqsrVJy8vT1arVSkpKR59d4bxAQCm0Jbvs4+JiVG/fv3c2qKiotS5c2dX++TJkzVz5kzFxcXJarVq+vTpstvtuvTSSyVJw4cPV0pKiiZNmqTFixeroqJCc+bMUWZm5ilHE74PyR4AYArev/XOt4PhS5YsUVBQkCZMmKD6+nqlp6fr2Wefde0PDg7WunXrNHXqVNntdkVFRSkjI0MLFy70+FokewAA2sCmTZvcPoeHhys7O1vZ2dmnPSY5OVnr16/3+tokewCAKXj/bPz2u8yNZA8AMAWnYZHTm/vs2/Fb79rvrykAAKBFqOwBAKbg9HIY35sH8vgbyR4AYArevLmu+fj2qv1GDgAAWoTKHgBgCg5Z5PDioTreHOtvJHsAgCkwjA8AAAIWlT0AwBQc8m4o3uG7UNocyR4AYApmHsYn2QMATOFsexFOW2q/kQMAgBahsgcAmILh5fvsDW69AwDg7MYwPgAACFhU9gAAUzDzK25J9gAAU3B4+dY7b471t/YbOQAAaBEqewCAKTCMDwBAgHMqSE4vBrS9Odbf2m/kAACgRajsAQCm4DAscngxFO/Nsf5GsgcAmAJz9gAABDjDy7feGTxBDwAAnK2o7AEApuCQRQ4vXmbjzbH+RrIHAJiC0/Bu3t1p+DCYNsYwPgAAAY7KHm5efjpeL2QlatxtX2rqwoOu9j3bI5XzaFft2xGp4GCp54++0cO5+xUWceJX3dynEvTPd6z6dHeEQkINvb5vl7++AvCD+g2u0f9355e6IPW4OtuaNP/W81SwIda1PzzSocm/LZc9vVrWTk2qKAvVX5/vor//sYsfo4a3nF4u0PPmWH8j2cOluChCf/9TZ/VI+catfc/2SP124vm6flql7nzwoIKDDX26J0KW//lz39Rg0ZAxR9T3klq99efObRw54JnwSKc+3R2ut/4cp3kvfHbS/v+bf0gDf1ajxdO7q7IsVBdfcUzTs77Q15UdtPXt2JNPiHbBKYucXsy7e3Osv50Vv6ZkZ2frvPPOU3h4uAYPHqx//vOf/g7JdL6pDdKj05J192Nliol1uO1bMf9cjZv8pX4xvUrn9a5TUq96XXHNEYWGfTuBddO9FRp/+5fq0aeurUMHPLb9PateXNxVWzacOnGnXHJcea/GaWdBtCq/CNWbqzrr0z0R6j3weBtHivZs2bJl6t+/v6xWq6xWq+x2u958803X/qFDh8pisbhtd9xxh9s5SktLNXr0aEVGRio+Pl733nuvmpqaPI7F78n+5Zdf1syZMzVv3jzt2LFDAwYMUHp6uqqqqvwdmqk885tu+smwal08pMat/chXIdq3I0odOzfp7jEX6Bf9f6R7xvfSxx9G+SlSoPXt2R6pS4cfVWdboyRDA35ao3N71qswP8bfocELzU/Q82bzRLdu3fTII4+osLBQ27dv11VXXaWxY8dq9+7drj5TpkxReXm5a1u8ePG38TocGj16tBoaGrRlyxa9+OKLysnJ0dy5cz3+7n5P9k888YSmTJmiW265RSkpKVq+fLkiIyP1wgsv+Ds009i0pqNKdkXo1tnlJ+0r/zxUkvTHJ2waOfFrPbTqU/VKPa77f3G+Dn4a2tahAm3i2TnnqvTf4crdsUd//3ynHlz1qbJ/c64+/jDa36HBC81z9t5snhgzZoxGjRqlCy64QBdeeKEeeughRUdHa+vWra4+kZGRstlsrs1qtbr2vf3229qzZ4/+9Kc/aeDAgRo5cqQWLVqk7OxsNTQ0eBSLX5N9Q0ODCgsLlZaW5moLCgpSWlqaCgoKTupfX1+v6upqtw3eqTrYQcvmnqtZz3yu0PCT7ytxOk/8c9Qvv1b69YfVK/Ub3bHgkLqdX6+3VjM3j8A09tav1GfQcc3NOE/TRlyo5xYmKvPhg7ro8mP+Dg1nge/mofr6+h88xuFwaPXq1aqtrZXdbne1r1q1Sl26dFG/fv00e/ZsHT/+7VRRQUGBUlNTlZCQ4GpLT09XdXW12+hAS/h1gd5XX30lh8Ph9kUkKSEhQfv27Tupf1ZWlhYsWNBW4ZlCyc5IHfmqgzLTe7vanA6Ldm2N0t9WdtHz7++VJCVf6D4Xn9SrTlUHO7RprEBbCA136ub7K7Rw8nn658YTVdaBvRHq+aNvdO0dX+pf7zOU31455eWz8f+7QC8pKcmtfd68eZo/f/4pj9m1a5fsdrvq6uoUHR2tN954QykpKZKkG2+8UcnJyUpMTNTOnTs1a9YsFRcX6/XXX5ckVVRUnDI/Nu/zRLtajT979mzNnDnT9bm6uvqkf+nwzMDLj2nFu+6/WP1uRncl9arTdZlV6prcoM62Bn2xP8ytz8FPw3TJVVQ5CDwhIYY6hBquUa1mTodkCWrHT1WBDC9X4xv/PbasrMxtuD0sLOx0h6h3794qKirS0aNH9dprrykjI0P5+flKSUnR7bff7uqXmpqqrl27atiwYdq/f7/OP//8M47zVPya7Lt06aLg4GBVVla6tVdWVspms53UPyws7Hv/pcJzkdFOnfedFfThkU7FdHK42q+d+qX++LhNPVO+Uc8ffaN3Xo1T2f5wzXnuM9cxVV900LEjIao62EFOh7T/4whJUmKPekVEfedvTcDPwiMdSuzx7ZynLalBPX/0jY4dCdaXB0P10ZYoTXmgXA11Qar8ooP622uVdu1/9PsFiX6MGt7y1VvvmlfXt0RoaKh69eolSRo0aJC2bdump556SitWrDip7+DBgyVJJSUlOv/882Wz2U66O605X54qR34fvyb70NBQDRo0SBs3btS4ceMkSU6nUxs3btS0adP8GRr+x/gpX6qxzqLl887VsSPB6plSp6w/71fied/+ZfnS412V90qc6/Odw09MCyx+rUQDflpz0jkBf7pwwDd67C/7XZ/vWHBIkvT2y530uxndlTU1Wbf+plyznvlcMR0dqjoYqpxHu2rdS6xTgXecTudp5/iLiookSV27dpUk2e12PfTQQ6qqqlJ8fLwkKS8vT1ar1TUV0FIWwzD8Oi718ssvKyMjQytWrNBPfvITPfnkk3rllVe0b9++k+Yqvqu6ulqxsbH6z797yhrj9xsLgFaRnjjQ3yEArabJaNQm/VVHjx5tcbXsqeZc8fO8W9Qh6szvImqsbdAbV69scayzZ8/WyJEj1b17dx07dky5ubl69NFH9dZbb6lnz57Kzc3VqFGj1LlzZ+3cuVMzZsxQt27dlJ+fL+nEor6BAwcqMTFRixcvVkVFhSZNmqTbbrtNDz/8sEex+33O/he/+IW+/PJLzZ07VxUVFRo4cKA2bNjwg4keAABP+GoYv6Wqqqp00003qby8XLGxserfv7/eeustXX311SorK9M777yjJ598UrW1tUpKStKECRM0Z84c1/HBwcFat26dpk6dKrvdrqioKGVkZGjhwoUex+73yt4bVPYwAyp7BLK2rOzHvn2r15X9X4e/0Kqxtha/V/YAALQFMz8bn2QPADCFth7GP5sw9g0AQICjsgcAmIKZK3uSPQDAFMyc7BnGBwAgwFHZAwBMwcyVPckeAGAKhry7fa7dPpRGJHsAgEmYubJnzh4AgABHZQ8AMAUzV/YkewCAKZg52TOMDwBAgKOyBwCYgpkre5I9AMAUDMMiw4uE7c2x/sYwPgAAAY7KHgBgCrzPHgCAAGfmOXuG8QEACHBU9gAAUzDzAj2SPQDAFMw8jE+yBwCYgpkre+bsAQAIcFT2AABTMLwcxm/PlT3JHgBgCoYkw/Du+PaKYXwAAAIclT0AwBScssjCE/QAAAhcrMYHAAABi8oeAGAKTsMiCw/VAQAgcBmGl6vx2/FyfIbxAQBoBcuWLVP//v1ltVpltVplt9v15ptvuvbX1dUpMzNTnTt3VnR0tCZMmKDKykq3c5SWlmr06NGKjIxUfHy87r33XjU1NXkcC8keAGAKzQv0vNk80a1bNz3yyCMqLCzU9u3bddVVV2ns2LHavXu3JGnGjBlau3atXn31VeXn5+vQoUMaP36863iHw6HRo0eroaFBW7Zs0YsvvqicnBzNnTvX4+9uMYz2OzBRXV2t2NhY/effPWWN4fcWBKb0xIH+DgFoNU1Gozbprzp69KisVmurXKM5V/T98ywFR4ad8Xkcx+u194ZHVVZW5hZrWFiYwsJadt64uDg99thjuvbaa3XOOecoNzdX1157rSRp37596tu3rwoKCnTppZfqzTff1P/7f/9Phw4dUkJCgiRp+fLlmjVrlr788kuFhoa2OHYyJADAFJrfeufNJklJSUmKjY11bVlZWT94bYfDodWrV6u2tlZ2u12FhYVqbGxUWlqaq0+fPn3UvXt3FRQUSJIKCgqUmprqSvSSlJ6erurqatfoQEuxQA8AAA+cqrI/nV27dslut6uurk7R0dF64403lJKSoqKiIoWGhqpjx45u/RMSElRRUSFJqqiocEv0zfub93mCZA8AMAVfrcZvXnDXEr1791ZRUZGOHj2q1157TRkZGcrPzz/zIM4QyR4AYAonkr03T9Dz/JjQ0FD16tVLkjRo0CBt27ZNTz31lH7xi1+ooaFBR44ccavuKysrZbPZJEk2m03//Oc/3c7XvFq/uU9LMWcPAEAbcTqdqq+v16BBg9ShQwdt3LjRta+4uFilpaWy2+2SJLvdrl27dqmqqsrVJy8vT1arVSkpKR5dl8oeAGAKbf1s/NmzZ2vkyJHq3r27jh07ptzcXG3atElvvfWWYmNjNXnyZM2cOVNxcXGyWq2aPn267Ha7Lr30UknS8OHDlZKSokmTJmnx4sWqqKjQnDlzlJmZ2eLV/81I9gAAUzDk3TvpPT22qqpKN910k8rLyxUbG6v+/fvrrbfe0tVXXy1JWrJkiYKCgjRhwgTV19crPT1dzz77rOv44OBgrVu3TlOnTpXdbldUVJQyMjK0cOFCj2Mn2QMA0Aqef/75790fHh6u7OxsZWdnn7ZPcnKy1q9f73UsJHsAgCmY+RW3JHsAgDm09Tj+WYRkDwAwBy8re7Xjyp5b7wAACHBU9gAAUzDz++xJ9gAAUzDzAj2G8QEACHBU9gAAczAs3i2ya8eVPckeAGAKZp6zZxgfAIAAR2UPADAHHqoDAEBgM/Nq/BYl+7/97W8tPuE111xzxsEAAADfa1GyHzduXItOZrFY5HA4vIkHAIDW046H4r3RomTvdDpbOw4AAFqVmYfxvVqNX1dX56s4AABoXYYPtnbK42TvcDi0aNEinXvuuYqOjtann34qSXrggQf0/PPP+zxAAADgHY+T/UMPPaScnBwtXrxYoaGhrvZ+/frpD3/4g0+DAwDAdyw+2Nonj5P9Sy+9pN///veaOHGigoODXe0DBgzQvn37fBocAAA+wzB+yx08eFC9evU6qd3pdKqxsdEnQQEAAN/xONmnpKTo/fffP6n9tdde00UXXeSToAAA8DkTV/YeP0Fv7ty5ysjI0MGDB+V0OvX666+ruLhYL730ktatW9caMQIA4D0Tv/XO48p+7NixWrt2rd555x1FRUVp7ty52rt3r9auXaurr766NWIEAABeOKNn419++eXKy8vzdSwAALQaM7/i9oxfhLN9+3bt3btX0ol5/EGDBvksKAAAfI633rXcF198oRtuuEH/+Mc/1LFjR0nSkSNH9NOf/lSrV69Wt27dfB0jAADwgsdz9rfddpsaGxu1d+9eHT58WIcPH9bevXvldDp12223tUaMAAB4r3mBnjdbO+VxZZ+fn68tW7aod+/errbevXvr6aef1uWXX+7T4AAA8BWLcWLz5vj2yuNkn5SUdMqH5zgcDiUmJvokKAAAfM7Ec/YeD+M/9thjmj59urZv3+5q2759u+666y49/vjjPg0OAAB4r0WVfadOnWSxfDtXUVtbq8GDBysk5MThTU1NCgkJ0a233qpx48a1SqAAAHjFxA/VaVGyf/LJJ1s5DAAAWlkbD+NnZWXp9ddf1759+xQREaGf/vSnevTRR93WvA0dOlT5+flux/3f//2fli9f7vpcWlqqqVOn6r333lN0dLQyMjKUlZXlKrhbokU9MzIyWnxCAABwYkF7ZmamfvzjH6upqUm/+c1vNHz4cO3Zs0dRUVGuflOmTNHChQtdnyMjI10/OxwOjR49WjabTVu2bFF5ebluuukmdejQQQ8//HCLYznjh+pIUl1dnRoaGtzarFarN6cEAKB1+Kiyr66udmsOCwtTWFjYSd03bNjg9jknJ0fx8fEqLCzUkCFDXO2RkZGy2WynvOTbb7+tPXv26J133lFCQoIGDhyoRYsWadasWZo/f75CQ0NbFLrHC/Rqa2s1bdo0xcfHKyoqSp06dXLbAAA4K/norXdJSUmKjY11bVlZWS26/NGjRyVJcXFxbu2rVq1Sly5d1K9fP82ePVvHjx937SsoKFBqaqoSEhJcbenp6aqurtbu3btb/NU9ruzvu+8+vffee1q2bJkmTZqk7OxsHTx4UCtWrNAjjzzi6ekAAGhXysrK3EaxT1XVf5fT6dTdd9+tn/3sZ+rXr5+r/cYbb1RycrISExO1c+dOzZo1S8XFxXr99dclSRUVFW6JXpLrc0VFRYtj9jjZr127Vi+99JKGDh2qW265RZdffrl69eql5ORkrVq1ShMnTvT0lAAAtD4frca3Wq0eT1lnZmbq448/1gcffODWfvvtt7t+Tk1NVdeuXTVs2DDt379f559//pnH+h0eD+MfPnxYPXv2lHTiCx8+fFiSdNlll2nz5s0+CwwAAF9qfoKeN9uZmDZtmtatW6f33nvvB98fM3jwYElSSUmJJMlms6mystKtT/Pn083zn4rHyb5nz546cOCAJKlPnz565ZVXJJ2o+JtfjAMAgNkZhqFp06bpjTfe0LvvvqsePXr84DFFRUWSpK5du0qS7Ha7du3apaqqKlefvLw8Wa1WpaSktDgWj4fxb7nlFn300Ue64oordP/992vMmDF65pln1NjYqCeeeMLT0wEA0Dba+D77zMxM5ebm6q9//atiYmJcc+yxsbGKiIjQ/v37lZubq1GjRqlz587auXOnZsyYoSFDhqh///6SpOHDhyslJUWTJk3S4sWLVVFRoTlz5igzM7NFawWaeZzsZ8yY4fo5LS1N+/btU2FhoXr16uUKDgAAs1u2bJmkEw/O+V8rV67UzTffrNDQUL3zzjt68sknVVtbq6SkJE2YMEFz5sxx9Q0ODta6des0depU2e12RUVFKSMjw+2+/Jbw6j57SUpOTlZycrK3pwEAoFVZ5OVb7zzsbxjff7GkpKSTnp53KsnJyVq/fr2HV3fXomS/dOnSFp/wV7/61RkHAwAAfK9FyX7JkiUtOpnFYvFLsp9w0WCFWFr2FCGgvQk5N9bfIQCtx1kvHWqja/EinO/XvPoeAIB2i/fZAwCAQOX1Aj0AANoFE1f2JHsAgCl48xS85uPbK4bxAQAIcFT2AABzMPEw/hlV9u+//75++ctfym636+DBg5KkP/7xjye9zQcAgLOGj95n3x55nOz/8pe/KD09XREREfrXv/6l+vp6SdLRo0f18MMP+zxAAADgHY+T/YMPPqjly5frueeeU4cOHVztP/vZz7Rjxw6fBgcAgK/46xW3ZwOP5+yLi4s1ZMiQk9pjY2N15MgRX8QEAIDvmfgJeh5X9jabTSUlJSe1f/DBB+rZs6dPggIAwOeYs2+5KVOm6K677tKHH34oi8WiQ4cOadWqVbrnnns0derU1ogRAAB4weNh/Pvvv19Op1PDhg3T8ePHNWTIEIWFhemee+7R9OnTWyNGAAC8ZuaH6nic7C0Wi37729/q3nvvVUlJiWpqapSSkqLo6OjWiA8AAN8w8X32Z/xQndDQUKWkpPgyFgAA0Ao8TvZXXnmlLJbTr0h89913vQoIAIBW4e3tc2aq7AcOHOj2ubGxUUVFRfr444+VkZHhq7gAAPAthvFbbsmSJadsnz9/vmpqarwOCAAA+JbP3nr3y1/+Ui+88IKvTgcAgG+Z+D57n731rqCgQOHh4b46HQAAPsWtdx4YP36822fDMFReXq7t27frgQce8FlgAADANzxO9rGxsW6fg4KC1Lt3by1cuFDDhw/3WWAAAMA3PEr2DodDt9xyi1JTU9WpU6fWigkAAN8z8Wp8jxboBQcHa/jw4bzdDgDQ7pj5Fbcer8bv16+fPv3009aIBQAAtAKPk/2DDz6oe+65R+vWrVN5ebmqq6vdNgAAzlomvO1O8mDOfuHChfr1r3+tUaNGSZKuueYat8fmGoYhi8Uih8Ph+ygBAPCWiefsW5zsFyxYoDvuuEPvvfdea8YDAAB8rMXD+IZx4leaK6644ns3AADORm29QC8rK0s//vGPFRMTo/j4eI0bN07FxcVuferq6pSZmanOnTsrOjpaEyZMUGVlpVuf0tJSjR49WpGRkYqPj9e9996rpqYmj2LxaM7++952BwDAWa2NH5ebn5+vzMxMbd26VXl5eWpsbNTw4cNVW1vr6jNjxgytXbtWr776qvLz83Xo0CG3h9c5HA6NHj1aDQ0N2rJli1588UXl5ORo7ty5HsXi0X32F1544Q8m/MOHD3sUAAAAgWjDhg1un3NychQfH6/CwkINGTJER48e1fPPP6/c3FxdddVVkqSVK1eqb9++2rp1qy699FK9/fbb2rNnj9555x0lJCRo4MCBWrRokWbNmqX58+crNDS0RbF4lOwXLFhw0hP0AABoD3z1bPzv3nkWFhamsLCwHzz+6NGjkqS4uDhJUmFhoRobG5WWlubq06dPH3Xv3l0FBQW69NJLVVBQoNTUVCUkJLj6pKena+rUqdq9e7cuuuiiFsXuUbK//vrrFR8f78khAACcHXy0Gj8pKcmted68eZo/f/73Hup0OnX33XfrZz/7mfr16ydJqqioUGhoqDp27OjWNyEhQRUVFa4+/5vom/c372upFid75usBAJDKyspktVpdn1tS1WdmZurjjz/WBx980JqhnZbHq/EBAGiXfLRAz2q1um0/lOynTZumdevW6b333lO3bt1c7TabTQ0NDSc9gr6yslI2m83V57ur85s/N/dpiRYne6fTyRA+AKDdautb7wzD0LRp0/TGG2/o3XffVY8ePdz2Dxo0SB06dNDGjRtdbcXFxSotLZXdbpck2e127dq1S1VVVa4+eXl5slqtSklJaXEsHr/iFgCAdqmNn6CXmZmp3Nxc/fWvf1VMTIxrjj02NlYRERGKjY3V5MmTNXPmTMXFxclqtWr69Omy2+269NJLJUnDhw9XSkqKJk2apMWLF6uiokJz5sxRZmZmi6YPmpHsAQBoBcuWLZMkDR061K195cqVuvnmmyVJS5YsUVBQkCZMmKD6+nqlp6fr2WefdfUNDg7WunXrNHXqVNntdkVFRSkjI0MLFy70KBaSPQDAHNq4sm/JWrfw8HBlZ2crOzv7tH2Sk5O1fv16zy7+HSR7AIAp+Oo++/bI41fcAgCA9oXKHgBgDrziFgCAwMYwPgAACFhU9gAAc2AYHwCAAGfiZM8wPgAAAY7KHgBgCpb/bt4c316R7AEA5mDiYXySPQDAFLj1DgAABCwqewCAOTCMDwCACbTjhO0NhvEBAAhwVPYAAFMw8wI9kj0AwBxMPGfPMD4AAAGOyh4AYAoM4wMAEOgYxgcAAIGKyh4AYAoM4wMAEOhMPIxPsgcAmIOJkz1z9gAABDgqewCAKTBnDwBAoGMYHwAABCoqewCAKVgMQxbjzMtzb471N5I9AMAcGMYHAACBimQPADCF5tX43mye2Lx5s8aMGaPExERZLBatWbPGbf/NN98si8Xito0YMcKtz+HDhzVx4kRZrVZ17NhRkydPVk1NjcffnWQPADAHwwebB2prazVgwABlZ2efts+IESNUXl7u2v785z+77Z84caJ2796tvLw8rVu3Tps3b9btt9/uWSBizh4AgFYxcuRIjRw58nv7hIWFyWaznXLf3r17tWHDBm3btk2XXHKJJOnpp5/WqFGj9PjjjysxMbHFsVDZAwBMwVfD+NXV1W5bfX39Gce0adMmxcfHq3fv3po6daq+/vpr176CggJ17NjRleglKS0tTUFBQfrwww89ug7JHgBgDj4axk9KSlJsbKxry8rKOqNwRowYoZdeekkbN27Uo48+qvz8fI0cOVIOh0OSVFFRofj4eLdjQkJCFBcXp4qKCo+uxTA+AMAUfPW43LKyMlmtVld7WFjYGZ3v+uuvd/2cmpqq/v376/zzz9emTZs0bNiwMw/0FKjsAQDwgNVqddvONNl/V8+ePdWlSxeVlJRIkmw2m6qqqtz6NDU16fDhw6ed5z8dkj0AwBzaeDW+p7744gt9/fXX6tq1qyTJbrfryJEjKiwsdPV599135XQ6NXjwYI/OzTA+AMA02vLNdTU1Na4qXZIOHDigoqIixcXFKS4uTgsWLNCECRNks9m0f/9+3XffferVq5fS09MlSX379tWIESM0ZcoULV++XI2NjZo2bZquv/56j1biS1T2AAC0iu3bt+uiiy7SRRddJEmaOXOmLrroIs2dO1fBwcHauXOnrrnmGl144YWaPHmyBg0apPfff99tWmDVqlXq06ePhg0bplGjRumyyy7T73//e49jobIHAJiDYZzYvDneA0OHDpXxPce89dZbP3iOuLg45ebmenTdUyHZAwBMwVer8dsjhvEBAAhwVPYAAHMw8StuSfYAAFOwOE9s3hzfXjGMDwBAgKOyx0lG31ih0TdUKKHbiZc7fP5JhHKfSdL2zZ0kSdMX7ddFPz2iuPhG1R0P0p4dMXrhsWR98WmkP8MGWuzGKZ9o4u0lbm1ln0Xpjv9viCRpxM9LdUV6uXr1PqrIaIeuuzJNtTUd/BEqfIlhfOBbX1WEauXjyTr4WbgsFint51Wau2yfpo0doNKSSJV8HKX3/tZFVYfCFBPbpF/+qkwPrdyjW64cJKfT4u/wgRb5bH+05mT+xPXZ0fTtn92wcId2FHTRjoIuunnav/0RHloBq/H9ZPPmzRozZowSExNlsVi0Zs0af4aD//rw3Thty++kQ59H6OBnEXpxSbLqjgerz8BjkqQ3X7bp422xqjoYrv17ovXiku6KT2xwjQQA7YHTYdF/vg5zbdVHQ137/vrnHnr1xfO1b1dH/wUI32u+z96brZ3ya7Kvra3VgAEDlJ2d7c8w8D2CggxdMforhUc6tK8o5qT9YREODZ9QpfKyMH1ZHnqKMwBnp8Sk43pp/bt6fs0m3bOoSOckfOPvkIBW49dh/JEjR2rkyJEt7l9fX6/6+m+rx+rq6tYIC5LOu7BWT7yyS6FhTn1zPFiL7uyj0pJv5+RH31iuyfd9rogop8r2R+i3N/9ITY2s90T7ULy7o5YsSNUXn0cprku9bpxSosXPbdWd11+ub44zuxmoGMZvJ7KyshQbG+vakpKS/B1SwPriQIQyrxmgu6/tr7/n2vTrxZ+oe6/jrv3v/e0cTRs7QPfe+CMd/Cxcs58qVofQdnxfCkylcMs5+mBjV31WYtWOredo3l2XKCqmSZenlfs7NLSms/ytd62pXSX72bNn6+jRo66trKzM3yEFrKbGIJWXRqhkd7RyfpesT/dGaWzGt38RHq8J0aHPI/Txtlg9NL23knp+o58O/9qPEQNnrramgw6WRqlr0vEf7gy0Q+1qvCosLMztbUBoO5Yg47SVu8UiySJ1CG3Hv/bC1MIjmtT13ON69yvPXhuK9sXMw/jtKtmjbdz868+1fXNHVR0KU2SUQ0PHfKX+g6s159YU2ZLqNGTUV9rxQUcdPdxBXWz1uu7/DqqhLkjbNnX0d+hAi0y+a58+fP8cVZVHqPM59Zp4+ydyOqX8t7pKkjp1rlenzvWuSv+8Xsf0zfEQVVWEq6aahajtVhu/9e5sQrLHSTp2btQ9i0sUF9+g2mPBOrAvSnNuTdG//tFRcfEN6ndJtcbdXK5oa5OOfN1BH2+zauYvUnX0MH8Jon3oHF+n+x78SNbYBh39T6h2fxSnmbfYVX3kxMjhyPGlbg/dWfzch5KkJQtS9c66bn6JGfCGX5N9TU2NSkq+/T/UgQMHVFRUpLi4OHXv3t2PkZnbk7/pddp9h6tCNXdKShtGA/je4t8O/N79uc9doNznLmibYNBmGMb3k+3bt+vKK690fZ45c6YkKSMjQzk5OX6KCgAQkHhcrn8MHTpURjueAwEAoD1gzh4AYAoM4wMAEOicxonNm+PbKZI9AMAcTDxn366eoAcAADxHZQ8AMAWLvJyz91kkbY9kDwAwBxM/QY9hfAAAAhyVPQDAFLj1DgCAQMdqfAAAEKio7AEApmAxDFm8WGTnzbH+RrIHAJiD87+bN8e3UwzjAwAQ4Ej2AABTaB7G92bzxObNmzVmzBglJibKYrFozZo1bvsNw9DcuXPVtWtXRUREKC0tTZ988olbn8OHD2vixImyWq3q2LGjJk+erJqaGo+/O8keAGAOhg82D9TW1mrAgAHKzs4+5f7Fixdr6dKlWr58uT788ENFRUUpPT1ddXV1rj4TJ07U7t27lZeXp3Xr1mnz5s26/fbbPQtEzNkDAMzCR0/Qq66udmsOCwtTWFjYSd1HjhypkSNHnuZUhp588knNmTNHY8eOlSS99NJLSkhI0Jo1a3T99ddr79692rBhg7Zt26ZLLrlEkvT0009r1KhRevzxx5WYmNji0KnsAQDwQFJSkmJjY11bVlaWx+c4cOCAKioqlJaW5mqLjY3V4MGDVVBQIEkqKChQx44dXYlektLS0hQUFKQPP/zQo+tR2QMATMFXT9ArKyuT1Wp1tZ+qqv8hFRUVkqSEhAS39oSEBNe+iooKxcfHu+0PCQlRXFycq09LkewBAObgo2F8q9XqluzbA4bxAQBoYzabTZJUWVnp1l5ZWenaZ7PZVFVV5ba/qalJhw8fdvVpKZI9AMAULE7vN1/p0aOHbDabNm7c6Gqrrq7Whx9+KLvdLkmy2+06cuSICgsLXX3effddOZ1ODR482KPrMYwPADCHNn6ffU1NjUpKSlyfDxw4oKKiIsXFxal79+66++679eCDD+qCCy5Qjx499MADDygxMVHjxo2TJPXt21cjRozQlClTtHz5cjU2NmratGm6/vrrPVqJL5HsAQBoFdu3b9eVV17p+jxz5kxJUkZGhnJycnTfffeptrZWt99+u44cOaLLLrtMGzZsUHh4uOuYVatWadq0aRo2bJiCgoI0YcIELV261ONYSPYAAHNo41fcDh06VMb3jAZYLBYtXLhQCxcuPG2fuLg45ebmenbhUyDZAwBMwcxvvWOBHgAAAY7KHgBgDm28QO9sQrIHAJiDIe/eSd9+cz3JHgBgDszZAwCAgEVlDwAwB0Neztn7LJI2R7IHAJiDiRfoMYwPAECAo7IHAJiDU5LFy+PbKZI9AMAUWI0PAAACFpU9AMAcTLxAj2QPADAHEyd7hvEBAAhwVPYAAHMwcWVPsgcAmAO33gEAENi49Q4AAAQsKnsAgDkwZw8AQIBzGpLFi4TtbL/JnmF8AAACHJU9AMAcGMYHACDQeZns1X6TPcP4AAAEOCp7AIA5MIwPAECAcxryaiie1fgAAOBsRWUPADAHw3li8+b4dopkDwAwBxPP2TOMDwAwB6fh/eaB+fPny2KxuG19+vRx7a+rq1NmZqY6d+6s6OhoTZgwQZWVlb7+1pJI9gAAtJof/ehHKi8vd20ffPCBa9+MGTO0du1avfrqq8rPz9ehQ4c0fvz4VomDYXwAgDn4YRg/JCRENpvtpPajR4/q+eefV25urq666ipJ0sqVK9W3b19t3bpVl1566ZnHeQpU9gAAczD0bcI/o+3Eaaqrq922+vr6017yk08+UWJionr27KmJEyeqtLRUklRYWKjGxkalpaW5+vbp00fdu3dXQUGBz786yR4AAA8kJSUpNjbWtWVlZZ2y3+DBg5WTk6MNGzZo2bJlOnDggC6//HIdO3ZMFRUVCg0NVceOHd2OSUhIUEVFhc9jZhgfAGAOPhrGLysrk9VqdTWHhYWdsvvIkSNdP/fv31+DBw9WcnKyXnnlFUVERJx5HGeAyh4AYA5Op/ebJKvV6radLtl/V8eOHXXhhReqpKRENptNDQ0NOnLkiFufysrKU87xe4tkDwBAG6ipqdH+/fvVtWtXDRo0SB06dNDGjRtd+4uLi1VaWiq73e7zazOMDwAwhzZejX/PPfdozJgxSk5O1qFDhzRv3jwFBwfrhhtuUGxsrCZPnqyZM2cqLi5OVqtV06dPl91u9/lKfIlkDwAwizZO9l988YVuuOEGff311zrnnHN02WWXaevWrTrnnHMkSUuWLFFQUJAmTJig+vp6paen69lnnz3z+L4HyR4AgFawevXq790fHh6u7OxsZWdnt3osJHsAgDmY+BW3JHsAgCkYhlOGF2+u8+ZYfyPZAwDMwfD8ZTYnHd9OcesdAAABjsoeAGAOhpdz9u24sifZAwDMwemULF7Mu7fjOXuG8QEACHBU9gAAc2AYHwCAwGY4nTK8GMZvz7feMYwPAECAo7IHAJgDw/gAAAQ4pyFZzJnsGcYHACDAUdkDAMzBMCR5c599+63sSfYAAFMwnIYML4bxDZI9AABnOcMp7yp7br0DAABnKSp7AIApMIwPAECgM/EwfrtO9s2/ZTUZjX6OBGg9Qc56f4cAtJomZ4Oktqmam9To1TN1mtR+c027TvbHjh2TJG0+/pqfIwFaUa2/AwBa37FjxxQbG9sq5w4NDZXNZtMHFeu9PpfNZlNoaKgPompbFqMdT0I4nU4dOnRIMTExslgs/g7HFKqrq5WUlKSysjJZrVZ/hwP4FH++255hGDp27JgSExMVFNR6a8br6urU0NDg9XlCQ0MVHh7ug4jaVruu7IOCgtStWzd/h2FKVquVvwwRsPjz3bZaq6L/X+Hh4e0ySfsKt94BABDgSPYAAAQ4kj08EhYWpnnz5iksLMzfoQA+x59vBKp2vUAPAAD8MCp7AAACHMkeAIAAR7IHACDAkewBAAhwJHu0WHZ2ts477zyFh4dr8ODB+uc//+nvkACf2Lx5s8aMGaPExERZLBatWbPG3yEBPkWyR4u8/PLLmjlzpubNm6cdO3ZowIABSk9PV1VVlb9DA7xWW1urAQMGKDs729+hAK2CW+/QIoMHD9aPf/xjPfPMM5JOvJcgKSlJ06dP1/333+/n6ADfsVgseuONNzRu3Dh/hwL4DJU9flBDQ4MKCwuVlpbmagsKClJaWpoKCgr8GBkAoCVI9vhBX331lRwOhxISEtzaExISVFFR4aeoAAAtRbIHACDAkezxg7p06aLg4GBVVla6tVdWVspms/kpKgBAS5Hs8YNCQ0M1aNAgbdy40dXmdDq1ceNG2e12P0YGAGiJEH8HgPZh5syZysjI0CWXXKKf/OQnevLJJ1VbW6tbbrnF36EBXqupqVFJSYnr84EDB1RUVKS4uDh1797dj5EBvsGtd2ixZ555Ro899pgqKio0cOBALV26VIMHD/Z3WIDXNm3apCuvvPKk9oyMDOXk5LR9QICPkewBAAhwzNkDABDgSPYAAAQ4kj0AAAGOZA8AQIAj2QMAEOBI9gAABDiSPQAAAY5kDwBAgCPZA166+eabNW7cONfnoUOH6u67727zODZt2iSLxaIjR46cto/FYtGaNWtafM758+dr4MCBXsX12WefyWKxqKioyKvzADhzJHsEpJtvvlkWi0UWi0WhoaHq1auXFi5cqKampla/9uuvv65Fixa1qG9LEjQAeIsX4SBgjRgxQitXrlR9fb3Wr1+vzMxMdejQQbNnzz6pb0NDg0JDQ31y3bi4OJ+cBwB8hcoeASssLEw2m03JycmaOnWq0tLS9Le//U3St0PvDz30kBITE9W7d29JUllZma677jp17NhRcXFxGjt2rD777DPXOR0Oh2bOnKmOHTuqc+fOuu+++/Td10t8dxi/vr5es2bNUlJSksLCwtSrVy89//zz+uyzz1wvX+nUqZMsFotuvvlmSSdeIZyVlaUePXooIiJCAwYM0GuvveZ2nfXr1+vCCy9URESErrzySrc4W2rWrFm68MILFRkZqZ49e+qBBx5QY2PjSf1WrFihpKQkRUZG6rrrrtPRo0fd9v/hD39Q3759FR4erj59+ujZZ5/1OBYArYdkD9OIiIhQQ0OD6/PGjRtVXFysvLw8rVu3To2NjUpPT1dMTIzef/99/eMf/1B0dLRGjBjhOu53v/udcnJy9MILL+iDDz7Q4cOH9cYbb3zvdW+66Sb9+c9/1tKlS7V3716tWLFC0dHRSkpK0l/+8hdJUnFxscrLy/XUU09JkrKysvTSSy9p+fLl2r17t2bMmKFf/vKXys/Pl3Til5Lx48drzJgxKioq0m233ab777/f438nMTExysnJ0Z49e/TUU0/pueee05IlS9z6lJSU6JVXXtHatWu1YcMG/etf/9Kdd97p2r9q1SrNnTtXDz30kPbu3auHH35YDzzwgF588UWP4wHQSgwgAGVkZBhjx441DMMwnE6nkZeXZ4SFhRn33HOPa39CQoJRX1/vOuaPf/yj0bt3b8PpdLra6uvrjYiICOOtt94yDMMwunbtaixevNi1v7Gx0ejWrZvrWoZhGFdccYVx1113GYZhGMXFxYYkIy8v75Rxvvfee4Yk4z//+Y+rra6uzoiMjDS2bNni1nfy5MnGDTfcYBiGYcyePdtISUlx2z9r1qyTzvVdkow33njjtPsfe+wxY9CgQa7P8+bNM4KDg40vvvjC1fbmm28aQUFBRnl5uWEYhnH++ecbubm5budZtGiRYbfbDcMwjAMHDhiSjH/961+nvS6A1sWcPQLWunXrFB0drcbGRjmdTt14442aP3++a39qaqrbPP1HH32kkpISxcTEuJ2nrq5O+/fv19GjR1VeXq7Bgwe79oWEhOiSSy45aSi/WVFRkYKDg3XFFVe0OO6SkhIdP35cV199tVt7Q0ODLrroIknS3r173eKQJLvd3uJrNHv55Ze1dOlS7d+/XzU1NWpqapLVanXr0717d5177rlu13E6nSouLlZMTIz279+vyZMna8qUKa4+TU1Nio2N9TgeAK2DZI+AdeWVV2rZsmUKDQ1VYmKiQkLc/7hHRUW5fa6pqdGgQYO0atWqk851zjnnnFEMERERHh9TU1MjSfr73//ulmSlE+sQfKWgoEATJ07UggULlJ6ertjYWK1evVq/+93vPI71ueeeO+mXj+DgYJ/FCsA7JHsErKioKPXq1avF/S+++GK9/PLLio+PP6m6bda1a1d9+OGHGjJkiKQTFWxhYaEuvvjiU/ZPTU2V0+lUfn6+0tLSTtrfPLLgcDhcbSkpKQoLC1NpaelpRwT69u3rWmzYbOvWrT/8Jf/Hli1blJycrN/+9reuts8///ykfqWlpTp06JASExNd1wkKClLv3r2VkJCgxMREffrpp5o4caJH1wfQdligB/zXxIkT1aVLF40dO1bvv/++Dhw4oE2bNulXv/qVvvjiC0nSXXfdpUceeURr1qzRvn37dOedd37vPfLnnXeeMjIydOutt2rNmjWuc77yyiuSpOTkZFksFq1bt05ffvmlampqFBMTo3vuuUczZszQiy++qP3792vHjh16+umnXYve7rjjDn3yySe69957VVxcrNzcXOXk5Hj0fS+44AKVlpZq9erV2r9/v5YuXXrKxYbh4eHKyMjQRx99pPfff1+/+tWvdN1118lms0mSFixYoKysLC1dulT//ve/tWvXLq1cuVJPPPGER/EAaD0ke+C/IiMjtXnzZnXv3l3jx49X3759NXnyZNXV1bkq/V//+teaNGmSMjIyZLfbFRMTo5///Offe95ly5bp2muv1Z133qk+ffpoypQpqq2tlSSde+65WrBgge6//34lJCRo2rRpkqRFixbpgQceUFZWlvr27asRI0bo73//u3r06CHpxDz6X/7yF61Zs0YDBgzQ8uXL9fDDD3v0fa+55hrNmDFD06ZN08CBA7VlyxY98MADJ/Xr1auXxo8fr1GjRmn48OHq37+/2611t912m/7whz9o5cqVSk1N1RVXXKGcnBxXrAD8z2KcbmURAAAICFT2AAAEOJI9AAABjmQPAECAI9kDABDgSPYAAAQ4kj0AAAGOZA8AQIAj2QMAEOBI9gAABDiSPQAAAY5kDwBAgPv/AVNp54ZMVSN4AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix=confusion_matrix)\n",
    "\n",
    "\n",
    "cm_display.plot()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Get the unique labels from y_test\n",
    "labels = y_test.value_counts().index\n",
    "\n",
    "sns.heatmap(\n",
    "    cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels\n",
    ")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
