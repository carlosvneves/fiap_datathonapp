{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "R_2Xop8am5Yo"
      },
      "outputs": [],
      "source": [
        "from autogluon.tabular import TabularDataset, TabularPredictor\n",
        "\n",
        "# import pandas\n",
        "import pandas as pd\n",
        "\n",
        "# import train-test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import KBinsDiscretizer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Previsão do ranking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>nome</th>\n",
              "      <th>ida</th>\n",
              "      <th>diff_fase</th>\n",
              "      <th>ponto_virada_encoded</th>\n",
              "      <th>anos_pm</th>\n",
              "      <th>bolsista_encoded</th>\n",
              "      <th>ipv</th>\n",
              "      <th>corraca</th>\n",
              "      <th>ponto_virada</th>\n",
              "      <th>ian</th>\n",
              "      <th>...</th>\n",
              "      <th>idade</th>\n",
              "      <th>sexo_encoded</th>\n",
              "      <th>fase</th>\n",
              "      <th>inde</th>\n",
              "      <th>sexo</th>\n",
              "      <th>na_fase</th>\n",
              "      <th>ano</th>\n",
              "      <th>cg</th>\n",
              "      <th>cf</th>\n",
              "      <th>ct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ALUNO-2</td>\n",
              "      <td>8.816667</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.916665</td>\n",
              "      <td>B</td>\n",
              "      <td>Não</td>\n",
              "      <td>5.0</td>\n",
              "      <td>...</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.675509</td>\n",
              "      <td>F</td>\n",
              "      <td>0</td>\n",
              "      <td>2022</td>\n",
              "      <td>245.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ALUNO-4</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.750000</td>\n",
              "      <td>R</td>\n",
              "      <td>Não</td>\n",
              "      <td>5.0</td>\n",
              "      <td>...</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>5.076252</td>\n",
              "      <td>M</td>\n",
              "      <td>0</td>\n",
              "      <td>2020</td>\n",
              "      <td>451.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ALUNO-4</td>\n",
              "      <td>5.083333</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.055553</td>\n",
              "      <td>R</td>\n",
              "      <td>Não</td>\n",
              "      <td>5.0</td>\n",
              "      <td>...</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>7.117065</td>\n",
              "      <td>M</td>\n",
              "      <td>0</td>\n",
              "      <td>2022</td>\n",
              "      <td>451.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ALUNO-5</td>\n",
              "      <td>7.500000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.166665</td>\n",
              "      <td>R</td>\n",
              "      <td>Não</td>\n",
              "      <td>10.0</td>\n",
              "      <td>...</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>8.077085</td>\n",
              "      <td>M</td>\n",
              "      <td>1</td>\n",
              "      <td>2020</td>\n",
              "      <td>415.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>12.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ALUNO-5</td>\n",
              "      <td>5.400000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.400000</td>\n",
              "      <td>R</td>\n",
              "      <td>Não</td>\n",
              "      <td>10.0</td>\n",
              "      <td>...</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>7.399000</td>\n",
              "      <td>M</td>\n",
              "      <td>1</td>\n",
              "      <td>2021</td>\n",
              "      <td>415.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>12.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 26 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      nome       ida  diff_fase  ponto_virada_encoded  anos_pm  \\\n",
              "0  ALUNO-2  8.816667       -2.0                     0      0.0   \n",
              "1  ALUNO-4  0.000000       -1.0                     0      2.0   \n",
              "2  ALUNO-4  5.083333       -1.0                     0      0.0   \n",
              "3  ALUNO-5  7.500000        0.0                     0      1.0   \n",
              "4  ALUNO-5  5.400000        0.0                     0      2.0   \n",
              "\n",
              "   bolsista_encoded       ipv corraca ponto_virada   ian  ... idade  \\\n",
              "0                 0  7.916665       B          Não   5.0  ...  11.0   \n",
              "1                 0  7.750000       R          Não   5.0  ...  10.0   \n",
              "2                 0  8.055553       R          Não   5.0  ...  12.0   \n",
              "3                 0  8.166665       R          Não  10.0  ...  10.0   \n",
              "4                 0  7.400000       R          Não  10.0  ...  11.0   \n",
              "\n",
              "   sexo_encoded  fase      inde  sexo  na_fase   ano     cg    cf    ct  \n",
              "0           1.0     0  7.675509     F        0  2022  245.0  66.0   6.0  \n",
              "1           0.0     1  5.076252     M        0  2020  451.0  69.0   3.0  \n",
              "2           0.0     2  7.117065     M        0  2022  451.0  69.0   3.0  \n",
              "3           0.0     2  8.077085     M        1  2020  415.0  61.0  12.0  \n",
              "4           0.0     2  7.399000     M        1  2021  415.0  61.0  12.0  \n",
              "\n",
              "[5 rows x 26 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pd.read_csv(\"../data/df_pooled_ranking.csv\")\n",
        "data.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['nome', 'ida', 'diff_fase', 'ponto_virada_encoded', 'anos_pm',\n",
              "       'bolsista_encoded', 'ipv', 'corraca', 'ponto_virada', 'ian', 'pedra',\n",
              "       'pedra_encoded', 'iaa', 'ips', 'ieg', 'ipp', 'idade', 'sexo_encoded',\n",
              "       'fase', 'inde', 'sexo', 'na_fase', 'ano', 'cg', 'cf', 'ct'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.columns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1646 entries, 0 to 1645\n",
            "Data columns (total 19 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   ida               1646 non-null   float64\n",
            " 1   diff_fase         1646 non-null   float64\n",
            " 2   anos_pm           1646 non-null   float64\n",
            " 3   bolsista_encoded  1646 non-null   int64  \n",
            " 4   ipv               1646 non-null   float64\n",
            " 5   ponto_virada      1646 non-null   object \n",
            " 6   ian               1646 non-null   float64\n",
            " 7   pedra             1646 non-null   object \n",
            " 8   iaa               1646 non-null   float64\n",
            " 9   ips               1646 non-null   float64\n",
            " 10  ieg               1646 non-null   float64\n",
            " 11  ipp               1646 non-null   float64\n",
            " 12  idade             1646 non-null   float64\n",
            " 13  fase              1646 non-null   int64  \n",
            " 14  inde              1646 non-null   float64\n",
            " 15  sexo              1646 non-null   object \n",
            " 16  na_fase           1646 non-null   int64  \n",
            " 17  ano               1646 non-null   int64  \n",
            " 18  cg                1646 non-null   float64\n",
            "dtypes: float64(12), int64(4), object(3)\n",
            "memory usage: 244.5+ KB\n"
          ]
        }
      ],
      "source": [
        "data.drop(\n",
        "    columns=[\n",
        "        \"sexo_encoded\",\n",
        "        \"cf\",\n",
        "        \"ct\",\n",
        "        \"pedra_encoded\",\n",
        "        \"ponto_virada_encoded\",\n",
        "        \"nome\",\n",
        "        \"corraca\",\n",
        "    ],\n",
        "    inplace=True,\n",
        ")\n",
        "data.info()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "kbins = KBinsDiscretizer(n_bins=4, encode=\"ordinal\", strategy=\"quantile\")\n",
        "# binned = kbins.fit_transform(data[['cg']])\n",
        "data[\"cg_cat\"] = kbins.fit_transform(data[[\"cg\"]])\n",
        "data[\"cg_cat\"] = data[\"cg_cat\"].astype(\"category\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "UZEoWJdNpNq9",
        "outputId": "208ba243-9fd3-4afe-a725-e43a262d85ae"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ida</th>\n",
              "      <th>diff_fase</th>\n",
              "      <th>anos_pm</th>\n",
              "      <th>bolsista_encoded</th>\n",
              "      <th>ipv</th>\n",
              "      <th>ponto_virada</th>\n",
              "      <th>ian</th>\n",
              "      <th>pedra</th>\n",
              "      <th>iaa</th>\n",
              "      <th>ips</th>\n",
              "      <th>ieg</th>\n",
              "      <th>ipp</th>\n",
              "      <th>idade</th>\n",
              "      <th>fase</th>\n",
              "      <th>inde</th>\n",
              "      <th>sexo</th>\n",
              "      <th>na_fase</th>\n",
              "      <th>ano</th>\n",
              "      <th>cg</th>\n",
              "      <th>cg_cat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8.816667</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>7.916665</td>\n",
              "      <td>Não</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Ametista</td>\n",
              "      <td>10.00002</td>\n",
              "      <td>7.500</td>\n",
              "      <td>7.581705</td>\n",
              "      <td>5.6250</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>7.675509</td>\n",
              "      <td>F</td>\n",
              "      <td>False</td>\n",
              "      <td>t2</td>\n",
              "      <td>245.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>False</td>\n",
              "      <td>7.750000</td>\n",
              "      <td>Não</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Quartzo</td>\n",
              "      <td>8.00002</td>\n",
              "      <td>6.875</td>\n",
              "      <td>4.100000</td>\n",
              "      <td>7.1875</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>5.076252</td>\n",
              "      <td>M</td>\n",
              "      <td>False</td>\n",
              "      <td>t0</td>\n",
              "      <td>451.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.083333</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>8.055553</td>\n",
              "      <td>Não</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Ametista</td>\n",
              "      <td>10.00002</td>\n",
              "      <td>7.500</td>\n",
              "      <td>8.071429</td>\n",
              "      <td>6.2500</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>7.117065</td>\n",
              "      <td>M</td>\n",
              "      <td>False</td>\n",
              "      <td>t2</td>\n",
              "      <td>451.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7.500000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>False</td>\n",
              "      <td>8.166665</td>\n",
              "      <td>Não</td>\n",
              "      <td>10.0</td>\n",
              "      <td>Ametista</td>\n",
              "      <td>7.50002</td>\n",
              "      <td>7.500</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.4375</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>8.077085</td>\n",
              "      <td>M</td>\n",
              "      <td>True</td>\n",
              "      <td>t0</td>\n",
              "      <td>415.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.400000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>False</td>\n",
              "      <td>7.400000</td>\n",
              "      <td>Não</td>\n",
              "      <td>10.0</td>\n",
              "      <td>Ametista</td>\n",
              "      <td>7.40000</td>\n",
              "      <td>7.500</td>\n",
              "      <td>7.500000</td>\n",
              "      <td>8.5000</td>\n",
              "      <td>11</td>\n",
              "      <td>2</td>\n",
              "      <td>7.399000</td>\n",
              "      <td>M</td>\n",
              "      <td>True</td>\n",
              "      <td>t1</td>\n",
              "      <td>415.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        ida  diff_fase  anos_pm  bolsista_encoded       ipv ponto_virada  \\\n",
              "0  8.816667       -2.0      0.0             False  7.916665          Não   \n",
              "1  0.000000       -1.0      2.0             False  7.750000          Não   \n",
              "2  5.083333       -1.0      0.0             False  8.055553          Não   \n",
              "3  7.500000        0.0      1.0             False  8.166665          Não   \n",
              "4  5.400000        0.0      2.0             False  7.400000          Não   \n",
              "\n",
              "    ian     pedra       iaa    ips       ieg     ipp  idade fase      inde  \\\n",
              "0   5.0  Ametista  10.00002  7.500  7.581705  5.6250     11    0  7.675509   \n",
              "1   5.0   Quartzo   8.00002  6.875  4.100000  7.1875     10    1  5.076252   \n",
              "2   5.0  Ametista  10.00002  7.500  8.071429  6.2500     12    2  7.117065   \n",
              "3  10.0  Ametista   7.50002  7.500  8.000000  8.4375     10    2  8.077085   \n",
              "4  10.0  Ametista   7.40000  7.500  7.500000  8.5000     11    2  7.399000   \n",
              "\n",
              "  sexo  na_fase ano     cg cg_cat  \n",
              "0    F    False  t2  245.0    1.0  \n",
              "1    M    False  t0  451.0    2.0  \n",
              "2    M    False  t2  451.0    2.0  \n",
              "3    M     True  t0  415.0    1.0  \n",
              "4    M     True  t1  415.0    1.0  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# converts 'idade' to int\n",
        "data[\"idade\"] = data[\"idade\"].astype(int)\n",
        "\n",
        "# converts 'ian' to category\n",
        "data[\"ian\"] = data[\"ian\"].astype(\"category\")\n",
        "\n",
        "# converts 'sexo' to category\n",
        "data[\"sexo\"] = data[\"sexo\"].astype(\"category\")\n",
        "\n",
        "# converts 'pedra' to category\n",
        "data[\"pedra\"] = data[\"pedra\"].astype(\"category\")\n",
        "\n",
        "# converts 'ponto_virada' to category\n",
        "data[\"ponto_virada\"] = data[\"ponto_virada\"].astype(\"category\")\n",
        "\n",
        "# converts 'fase' to category\n",
        "data[\"fase\"] = data[\"fase\"].astype(\"category\")\n",
        "\n",
        "# converts 'na_fase' to boolean\n",
        "data[\"na_fase\"] = data[\"na_fase\"].astype(bool)\n",
        "\n",
        "# converts bolsista_encoded to boolean\n",
        "data[\"bolsista_encoded\"] = data[\"bolsista_encoded\"].astype(bool)\n",
        "\n",
        "# maps ano to t,t+1,t+2\n",
        "data[\"ano\"] = data[\"ano\"].apply(\n",
        "    lambda x: \"t0\" if x == 2020 else (\"t1\" if x == 2021 else \"t2\")\n",
        ")\n",
        "data[\"ano\"] = data[\"ano\"].astype(\"category\")\n",
        "\n",
        "data.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "cS49AhonolIC"
      },
      "outputs": [],
      "source": [
        "# Selecionar as variáveis preditoras e a variável alvo\n",
        "X = data.drop(columns=[\"cg\", \"cg_cat\"])\n",
        "\n",
        "# X = X[\n",
        "#     [\n",
        "#         \"inde\",\n",
        "#         \"ano\",\n",
        "#         \"pedra\",\n",
        "#         \"idade\",\n",
        "#         \"fase\",\n",
        "#         \"ipv\",\n",
        "#         \"diff_fase\",\n",
        "#         \"ipp\",\n",
        "#         \"ieg\",\n",
        "#         \"ian\",\n",
        "#         \"ponto_virada\",\n",
        "#         \"ida\",\n",
        "#         \"ips\",\n",
        "#         \"na_fase\",\n",
        "#         \"iaa\",\n",
        "#     ]\n",
        "# ]\n",
        "\n",
        "X = X[\n",
        "    [\n",
        "        \"inde\",\n",
        "        \"ano\",\n",
        "        \"ipv\",\n",
        "        \"pedra\",\n",
        "        \"na_fase\",\n",
        "        \"ida\",\n",
        "        \"ipp\",\n",
        "        \"idade\",\n",
        "        \"iaa\",\n",
        "        \"fase\",\n",
        "        \"ieg\",\n",
        "    ]\n",
        "]\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, data[\"cg_cat\"], test_size=0.25, random_state=41, shuffle=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "Kw7zBayDqUsu",
        "outputId": "d5af951d-b442-4ade-ac38-8016d3184e26"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>inde</th>\n",
              "      <th>ano</th>\n",
              "      <th>pedra</th>\n",
              "      <th>idade</th>\n",
              "      <th>fase</th>\n",
              "      <th>ipv</th>\n",
              "      <th>diff_fase</th>\n",
              "      <th>ipp</th>\n",
              "      <th>ieg</th>\n",
              "      <th>ian</th>\n",
              "      <th>ponto_virada</th>\n",
              "      <th>ida</th>\n",
              "      <th>ips</th>\n",
              "      <th>na_fase</th>\n",
              "      <th>iaa</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>425</th>\n",
              "      <td>6.764000</td>\n",
              "      <td>t1</td>\n",
              "      <td>Ágata</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>7.300000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.700000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>10.0</td>\n",
              "      <td>Não</td>\n",
              "      <td>4.200000</td>\n",
              "      <td>7.500</td>\n",
              "      <td>True</td>\n",
              "      <td>9.50000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1238</th>\n",
              "      <td>8.114724</td>\n",
              "      <td>t0</td>\n",
              "      <td>Ametista</td>\n",
              "      <td>14</td>\n",
              "      <td>3</td>\n",
              "      <td>7.944447</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>8.125000</td>\n",
              "      <td>9.400000</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Não</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>7.500</td>\n",
              "      <td>False</td>\n",
              "      <td>9.16668</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>266</th>\n",
              "      <td>7.765000</td>\n",
              "      <td>t1</td>\n",
              "      <td>Ametista</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>8.400000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>8.100000</td>\n",
              "      <td>8.800000</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Não</td>\n",
              "      <td>7.100000</td>\n",
              "      <td>7.500</td>\n",
              "      <td>False</td>\n",
              "      <td>8.50000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1058</th>\n",
              "      <td>7.680084</td>\n",
              "      <td>t2</td>\n",
              "      <td>Ametista</td>\n",
              "      <td>13</td>\n",
              "      <td>2</td>\n",
              "      <td>7.666663</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>6.458333</td>\n",
              "      <td>8.754579</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Não</td>\n",
              "      <td>8.500000</td>\n",
              "      <td>7.500</td>\n",
              "      <td>False</td>\n",
              "      <td>8.00002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1147</th>\n",
              "      <td>6.389726</td>\n",
              "      <td>t2</td>\n",
              "      <td>Ágata</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>8.166665</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>5.625000</td>\n",
              "      <td>6.948622</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Não</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>6.875</td>\n",
              "      <td>False</td>\n",
              "      <td>9.50002</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          inde ano     pedra  idade fase       ipv  diff_fase       ipp  \\\n",
              "425   6.764000  t1     Ágata      9    1  7.300000        0.0  7.700000   \n",
              "1238  8.114724  t0  Ametista     14    3  7.944447       -1.0  8.125000   \n",
              "266   7.765000  t1  Ametista     10    1  8.400000       -1.0  8.100000   \n",
              "1058  7.680084  t2  Ametista     13    2  7.666663       -1.0  6.458333   \n",
              "1147  6.389726  t2     Ágata     11    1  8.166665       -1.0  5.625000   \n",
              "\n",
              "           ieg   ian ponto_virada       ida    ips  na_fase      iaa  \n",
              "425   5.000000  10.0          Não  4.200000  7.500     True  9.50000  \n",
              "1238  9.400000   5.0          Não  8.333333  7.500    False  9.16668  \n",
              "266   8.800000   5.0          Não  7.100000  7.500    False  8.50000  \n",
              "1058  8.754579   5.0          Não  8.500000  7.500    False  8.00002  \n",
              "1147  6.948622   5.0          Não  3.333333  6.875    False  9.50002  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "O5_TcbsPqtUU"
      },
      "outputs": [],
      "source": [
        "train_data = pd.concat([X_train, y_train], axis=1)\n",
        "test_data = pd.concat([X_test, y_test], axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "dPhQ-wRprRka",
        "outputId": "73d9a411-01fb-42ee-c525-dc4317bf887f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>inde</th>\n",
              "      <th>ano</th>\n",
              "      <th>pedra</th>\n",
              "      <th>idade</th>\n",
              "      <th>fase</th>\n",
              "      <th>ipv</th>\n",
              "      <th>diff_fase</th>\n",
              "      <th>ipp</th>\n",
              "      <th>ieg</th>\n",
              "      <th>ian</th>\n",
              "      <th>ponto_virada</th>\n",
              "      <th>ida</th>\n",
              "      <th>ips</th>\n",
              "      <th>na_fase</th>\n",
              "      <th>iaa</th>\n",
              "      <th>cg_cat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>425</th>\n",
              "      <td>6.764000</td>\n",
              "      <td>t1</td>\n",
              "      <td>Ágata</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>7.300000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.700000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>10.0</td>\n",
              "      <td>Não</td>\n",
              "      <td>4.200000</td>\n",
              "      <td>7.500</td>\n",
              "      <td>True</td>\n",
              "      <td>9.50000</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1238</th>\n",
              "      <td>8.114724</td>\n",
              "      <td>t0</td>\n",
              "      <td>Ametista</td>\n",
              "      <td>14</td>\n",
              "      <td>3</td>\n",
              "      <td>7.944447</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>8.125000</td>\n",
              "      <td>9.400000</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Não</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>7.500</td>\n",
              "      <td>False</td>\n",
              "      <td>9.16668</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>266</th>\n",
              "      <td>7.765000</td>\n",
              "      <td>t1</td>\n",
              "      <td>Ametista</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>8.400000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>8.100000</td>\n",
              "      <td>8.800000</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Não</td>\n",
              "      <td>7.100000</td>\n",
              "      <td>7.500</td>\n",
              "      <td>False</td>\n",
              "      <td>8.50000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1058</th>\n",
              "      <td>7.680084</td>\n",
              "      <td>t2</td>\n",
              "      <td>Ametista</td>\n",
              "      <td>13</td>\n",
              "      <td>2</td>\n",
              "      <td>7.666663</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>6.458333</td>\n",
              "      <td>8.754579</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Não</td>\n",
              "      <td>8.500000</td>\n",
              "      <td>7.500</td>\n",
              "      <td>False</td>\n",
              "      <td>8.00002</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1147</th>\n",
              "      <td>6.389726</td>\n",
              "      <td>t2</td>\n",
              "      <td>Ágata</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>8.166665</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>5.625000</td>\n",
              "      <td>6.948622</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Não</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>6.875</td>\n",
              "      <td>False</td>\n",
              "      <td>9.50002</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          inde ano     pedra  idade fase       ipv  diff_fase       ipp  \\\n",
              "425   6.764000  t1     Ágata      9    1  7.300000        0.0  7.700000   \n",
              "1238  8.114724  t0  Ametista     14    3  7.944447       -1.0  8.125000   \n",
              "266   7.765000  t1  Ametista     10    1  8.400000       -1.0  8.100000   \n",
              "1058  7.680084  t2  Ametista     13    2  7.666663       -1.0  6.458333   \n",
              "1147  6.389726  t2     Ágata     11    1  8.166665       -1.0  5.625000   \n",
              "\n",
              "           ieg   ian ponto_virada       ida    ips  na_fase      iaa cg_cat  \n",
              "425   5.000000  10.0          Não  4.200000  7.500     True  9.50000    3.0  \n",
              "1238  9.400000   5.0          Não  8.333333  7.500    False  9.16668    1.0  \n",
              "266   8.800000   5.0          Não  7.100000  7.500    False  8.50000    0.0  \n",
              "1058  8.754579   5.0          Não  8.500000  7.500    False  8.00002    1.0  \n",
              "1147  6.948622   5.0          Não  3.333333  6.875    False  9.50002    3.0  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6r4bOOTZq2c2",
        "outputId": "8585806f-c22b-4035-9e61-f7e269a9ea6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Summary of class variable: \n",
            " count     1234.0\n",
            "unique       4.0\n",
            "top          1.0\n",
            "freq       316.0\n",
            "Name: cg_cat, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "label = \"cg_cat\"\n",
        "print(\"Summary of class variable: \\n\", train_data[label].describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "inde             float64\n",
              "ano             category\n",
              "pedra           category\n",
              "idade              int64\n",
              "fase            category\n",
              "ipv              float64\n",
              "diff_fase        float64\n",
              "ipp              float64\n",
              "ieg              float64\n",
              "ian             category\n",
              "ponto_virada    category\n",
              "ida              float64\n",
              "ips              float64\n",
              "na_fase             bool\n",
              "iaa              float64\n",
              "cg_cat          category\n",
              "dtype: object"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.dtypes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAc877E9rF-9",
        "outputId": "935d6784-1763-43b7-d229-223b4ba1e2e5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"agModels-predictRanking\"\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.1.1\n",
            "Python Version:     3.11.9\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Fri Mar 29 23:14:13 UTC 2024\n",
            "CPU Count:          16\n",
            "Memory Avail:       8.60 GB / 15.49 GB (55.6%)\n",
            "Disk Space Avail:   914.14 GB / 1006.85 GB (90.8%)\n",
            "===================================================\n",
            "Presets specified: ['good_quality']\n",
            "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
            "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
            "Note: `save_bag_folds=False`! This will greatly reduce peak disk usage during fit (by ~8x), but runs the risk of an out-of-memory error during model refit if memory is small relative to the data size.\n",
            "\tYou can avoid this risk by setting `save_bag_folds=True`.\n",
            "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
            "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
            "\tRunning DyStack for up to 300s of the 1200s of remaining time (25%).\n",
            "\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n",
            "2024-09-15 23:37:31,203\tINFO worker.py:1743 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
            "\t\tContext path: \"agModels-predictRanking/ds_sub_fit/sub_fit_ho\"\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m Running DyStack sub-fit ...\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m Beginning AutoGluon training ... Time limit = 294s\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m AutoGluon will save models to \"agModels-predictRanking/ds_sub_fit/sub_fit_ho\"\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m Train Data Rows:    1096\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m Train Data Columns: 15\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m Label Column:       cg_cat\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m Problem Type:       multiclass\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m Preprocessing data ...\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m Train Data Class Count: 4\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m Using Feature Generators to preprocess the data ...\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \tAvailable Memory:                    7262.98 MB\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \tTrain Data (Original)  Memory Usage: 0.08 MB (0.0% of available memory)\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \tStage 1 Generators:\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \tStage 2 Generators:\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \tStage 3 Generators:\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t\tFitting CategoryFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \tStage 4 Generators:\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \tStage 5 Generators:\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t\t('bool', [])     : 1 | ['na_fase']\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t\t('category', []) : 5 | ['ano', 'pedra', 'fase', 'ian', 'ponto_virada']\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t\t('float', [])    : 8 | ['inde', 'ipv', 'diff_fase', 'ipp', 'ieg', ...]\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t\t('int', [])      : 1 | ['idade']\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t\t('category', [])  : 4 | ['ano', 'pedra', 'fase', 'ian']\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t\t('float', [])     : 8 | ['inde', 'ipv', 'diff_fase', 'ipp', 'ieg', ...]\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t\t('int', [])       : 1 | ['idade']\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t\t('int', ['bool']) : 2 | ['ponto_virada', 'na_fase']\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t0.1s = Fit runtime\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t15 features in original data used to generate 15 features in processed data.\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \tTrain Data (Processed) Memory Usage: 0.08 MB (0.0% of available memory)\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m Data preprocessing and feature engineering runtime = 0.08s ...\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m User-specified model hyperparameters to be fit:\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m {\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t'NN_TORCH': {},\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t'CAT': {},\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t'XGB': {},\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t'FASTAI': {},\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t'RF': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t'XT': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m }\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m Fitting 11 L1 models ...\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 195.72s of the 293.65s of remaining time.\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=8, gpus=0, memory=0.01%)\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t0.7281\t = Validation score   (accuracy)\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t46.18s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t0.37s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 146.92s of the 244.85s of remaining time.\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.05%)\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t0.7427\t = Validation score   (accuracy)\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t1.92s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t0.1s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m Fitting model: LightGBM_BAG_L1 ... Training model for up to 141.71s of the 239.64s of remaining time.\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.06%)\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t0.7746\t = Validation score   (accuracy)\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t2.15s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t0.05s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 136.9s of the 234.83s of remaining time.\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t0.7409\t = Validation score   (accuracy)\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t1.86s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t0.15s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 134.78s of the 232.71s of remaining time.\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t0.7363\t = Validation score   (accuracy)\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t1.62s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t0.14s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m Fitting model: CatBoost_BAG_L1 ... Training model for up to 132.95s of the 230.88s of remaining time.\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=8, gpus=0, memory=0.09%)\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t0.7664\t = Validation score   (accuracy)\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t32.47s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t0.05s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 98.01s of the 195.94s of remaining time.\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t0.698\t = Validation score   (accuracy)\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t1.6s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t0.14s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 96.18s of the 194.11s of remaining time.\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t0.7044\t = Validation score   (accuracy)\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t1.62s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t0.14s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m Fitting model: XGBoost_BAG_L1 ... Training model for up to 94.32s of the 192.25s of remaining time.\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=8, gpus=0, memory=0.09%)\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t0.7619\t = Validation score   (accuracy)\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t29.64s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t0.14s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 62.32s of the 160.25s of remaining time.\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=8, gpus=0, memory=0.01%)\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t0.7318\t = Validation score   (accuracy)\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t76.73s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t0.18s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 293.65s of the 80.99s of remaining time.\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \tEnsemble Weights: {'LightGBM_BAG_L1': 0.958, 'NeuralNetTorch_BAG_L1': 0.042}\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t0.7755\t = Validation score   (accuracy)\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t0.17s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t0.0s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m Fitting 11 L2 models ...\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 80.8s of the 80.79s of remaining time.\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=8, gpus=0, memory=0.04%)\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t0.7746\t = Validation score   (accuracy)\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t65.91s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t0.31s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 12.35s of the 12.33s of remaining time.\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.18%)\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t0.7792\t = Validation score   (accuracy)\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t3.0s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t0.07s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m Fitting model: LightGBM_BAG_L2 ... Training model for up to 6.71s of the 6.69s of remaining time.\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.19%)\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t0.7728\t = Validation score   (accuracy)\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t5.81s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t0.06s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 293.65s of the -2.45s of remaining time.\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \tEnsemble Weights: {'LightGBMXT_BAG_L2': 1.0}\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t0.7792\t = Validation score   (accuracy)\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t0.27s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t0.0s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m AutoGluon training complete, total runtime = 296.48s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 133.2 rows/s (137 batch size)\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m Fitting 1 L1 models ...\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L1_FULL ...\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \tStopping at the best epoch learned earlier - 19.\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t1.67s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m Fitting 1 L1 models ...\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t0.36s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m Fitting 1 L1 models ...\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m Fitting model: LightGBM_BAG_L1_FULL ...\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t0.22s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m Fitting model: RandomForestGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t1.86s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t0.15s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m Fitting model: RandomForestEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t1.62s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t0.14s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m Fitting 1 L1 models ...\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m Fitting model: CatBoost_BAG_L1_FULL ...\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t1.12s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m Fitting model: ExtraTreesGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t1.6s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t0.14s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m Fitting model: ExtraTreesEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t1.62s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t0.14s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m Fitting 1 L1 models ...\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m Fitting model: XGBoost_BAG_L1_FULL ...\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t0.13s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m Fitting 1 L1 models ...\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m Fitting model: NeuralNetTorch_BAG_L1_FULL ...\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t5.04s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \tEnsemble Weights: {'LightGBM_BAG_L1': 0.958, 'NeuralNetTorch_BAG_L1': 0.042}\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t0.17s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m Fitting 1 L2 models ...\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L2_FULL ...\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \tStopping at the best epoch learned earlier - 8.\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t0.84s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m Fitting 1 L2 models ...\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t0.34s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m Fitting 1 L2 models ...\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m Fitting model: LightGBM_BAG_L2_FULL ...\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t0.39s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \tEnsemble Weights: {'LightGBMXT_BAG_L2': 1.0}\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m \t0.27s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m Updated best model to \"LightGBMXT_BAG_L2_FULL\" (Previously \"WeightedEnsemble_L3\"). AutoGluon will default to using \"LightGBMXT_BAG_L2_FULL\" for predict() and predict_proba().\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m Refit complete, total runtime = 13.1s ... Best model: \"LightGBMXT_BAG_L2_FULL\"\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels-predictRanking/ds_sub_fit/sub_fit_ho\")\n",
            "\u001b[36m(_dystack pid=209469)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
            "Leaderboard on holdout data (DyStack):\n",
            "                           model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0   RandomForestEntr_BAG_L1_FULL       0.717391   0.736314    accuracy        0.212793       0.142902   1.622467                 0.212793                0.142902           1.622467            1       True          5\n",
            "1   RandomForestGini_BAG_L1_FULL       0.717391   0.740876    accuracy        0.239073       0.151604   1.864422                 0.239073                0.151604           1.864422            1       True          4\n",
            "2         LightGBMXT_BAG_L2_FULL       0.717391   0.779197    accuracy        1.112767            NaN  15.593064                 0.038502                     NaN           0.342967            2       True         13\n",
            "3       WeightedEnsemble_L3_FULL       0.717391   0.779197    accuracy        1.116383            NaN  15.864863                 0.003617                     NaN           0.271799            3       True         15\n",
            "4       WeightedEnsemble_L2_FULL       0.702899   0.775547    accuracy        0.077749            NaN   5.429369                 0.003154                     NaN           0.166440            2       True         11\n",
            "5    NeuralNetFastAI_BAG_L2_FULL       0.702899   0.774635    accuracy        1.106494            NaN  16.094890                 0.032230                     NaN           0.844793            2       True         12\n",
            "6           LightGBM_BAG_L1_FULL       0.695652   0.774635    accuracy        0.049329            NaN   0.221063                 0.049329                     NaN           0.221063            1       True          3\n",
            "7    NeuralNetFastAI_BAG_L1_FULL       0.688406   0.728102    accuracy        0.028658            NaN   1.665275                 0.028658                     NaN           1.665275            1       True          1\n",
            "8     ExtraTreesEntr_BAG_L1_FULL       0.688406   0.704380    accuracy        0.212182       0.139804   1.621997                 0.212182                0.139804           1.621997            1       True          8\n",
            "9     ExtraTreesGini_BAG_L1_FULL       0.688406   0.697993    accuracy        0.222669       0.139486   1.604376                 0.222669                0.139486           1.604376            1       True          7\n",
            "10          CatBoost_BAG_L1_FULL       0.681159   0.766423    accuracy        0.009780            NaN   1.123242                 0.009780                     NaN           1.123242            1       True          6\n",
            "11        LightGBMXT_BAG_L1_FULL       0.681159   0.742701    accuracy        0.059239            NaN   0.359548                 0.059239                     NaN           0.359548            1       True          2\n",
            "12          LightGBM_BAG_L2_FULL       0.673913   0.772810    accuracy        1.118280            NaN  15.638718                 0.044016                     NaN           0.388621            2       True         14\n",
            "13           XGBoost_BAG_L1_FULL       0.666667   0.761861    accuracy        0.015275            NaN   0.125839                 0.015275                     NaN           0.125839            1       True          9\n",
            "14    NeuralNetTorch_BAG_L1_FULL       0.637681   0.731752    accuracy        0.025266            NaN   5.041867                 0.025266                     NaN           5.041867            1       True         10\n",
            "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
            "\t320s\t = DyStack   runtime |\t880s\t = Remaining runtime\n",
            "Starting main fit with num_stack_levels=1.\n",
            "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
            "Beginning AutoGluon training ... Time limit = 880s\n",
            "AutoGluon will save models to \"agModels-predictRanking\"\n",
            "Train Data Rows:    1234\n",
            "Train Data Columns: 15\n",
            "Label Column:       cg_cat\n",
            "Problem Type:       multiclass\n",
            "Preprocessing data ...\n",
            "Train Data Class Count: 4\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    6872.99 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.09 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('bool', [])     : 1 | ['na_fase']\n",
            "\t\t('category', []) : 5 | ['ano', 'pedra', 'fase', 'ian', 'ponto_virada']\n",
            "\t\t('float', [])    : 8 | ['inde', 'ipv', 'diff_fase', 'ipp', 'ieg', ...]\n",
            "\t\t('int', [])      : 1 | ['idade']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', [])  : 4 | ['ano', 'pedra', 'fase', 'ian']\n",
            "\t\t('float', [])     : 8 | ['inde', 'ipv', 'diff_fase', 'ipp', 'ieg', ...]\n",
            "\t\t('int', [])       : 1 | ['idade']\n",
            "\t\t('int', ['bool']) : 2 | ['ponto_virada', 'na_fase']\n",
            "\t0.1s = Fit runtime\n",
            "\t15 features in original data used to generate 15 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.09 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.18s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': {},\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
            "\t'CAT': {},\n",
            "\t'XGB': {},\n",
            "\t'FASTAI': {},\n",
            "\t'RF': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "}\n",
            "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
            "Fitting 11 L1 models ...\n",
            "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 586.72s of the 880.3s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=8, gpus=0, memory=0.02%)\n",
            "\t0.7237\t = Validation score   (accuracy)\n",
            "\t42.61s\t = Training   runtime\n",
            "\t0.23s\t = Validation runtime\n",
            "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 542.05s of the 835.62s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.05%)\n",
            "\t0.7447\t = Validation score   (accuracy)\n",
            "\t2.08s\t = Training   runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "Fitting model: LightGBM_BAG_L1 ... Training model for up to 536.46s of the 830.04s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.06%)\n",
            "\t0.7707\t = Validation score   (accuracy)\n",
            "\t3.08s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 530.18s of the 823.75s of remaining time.\n",
            "\t0.7318\t = Validation score   (accuracy)\n",
            "\t1.38s\t = Training   runtime\n",
            "\t0.14s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 528.57s of the 822.15s of remaining time.\n",
            "\t0.7318\t = Validation score   (accuracy)\n",
            "\t1.36s\t = Training   runtime\n",
            "\t0.17s\t = Validation runtime\n",
            "Fitting model: CatBoost_BAG_L1 ... Training model for up to 526.96s of the 820.54s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=8, gpus=0, memory=0.08%)\n",
            "\t0.7658\t = Validation score   (accuracy)\n",
            "\t38.29s\t = Training   runtime\n",
            "\t0.05s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 486.29s of the 779.87s of remaining time.\n",
            "\t0.6969\t = Validation score   (accuracy)\n",
            "\t1.31s\t = Training   runtime\n",
            "\t0.15s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 484.75s of the 778.33s of remaining time.\n",
            "\t0.6969\t = Validation score   (accuracy)\n",
            "\t1.33s\t = Training   runtime\n",
            "\t0.14s\t = Validation runtime\n",
            "Fitting model: XGBoost_BAG_L1 ... Training model for up to 483.04s of the 776.62s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=8, gpus=0, memory=0.09%)\n",
            "\t0.7569\t = Validation score   (accuracy)\n",
            "\t20.26s\t = Training   runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 460.45s of the 754.03s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=8, gpus=0, memory=0.01%)\n",
            "\t0.7245\t = Validation score   (accuracy)\n",
            "\t60.12s\t = Training   runtime\n",
            "\t0.17s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 398.64s of the 692.21s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.17%)\n",
            "\t0.7488\t = Validation score   (accuracy)\n",
            "\t5.09s\t = Training   runtime\n",
            "\t0.09s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 684.12s of remaining time.\n",
            "\tEnsemble Weights: {'LightGBM_BAG_L1': 0.846, 'CatBoost_BAG_L1': 0.077, 'XGBoost_BAG_L1': 0.077}\n",
            "\t0.7739\t = Validation score   (accuracy)\n",
            "\t0.17s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting 11 L2 models ...\n",
            "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 683.92s of the 683.9s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=8, gpus=0, memory=0.05%)\n",
            "\t0.7739\t = Validation score   (accuracy)\n",
            "\t41.93s\t = Training   runtime\n",
            "\t0.22s\t = Validation runtime\n",
            "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 639.56s of the 639.54s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.19%)\n",
            "\t0.7893\t = Validation score   (accuracy)\n",
            "\t4.35s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: LightGBM_BAG_L2 ... Training model for up to 632.16s of the 632.15s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.18%)\n",
            "\t0.7804\t = Validation score   (accuracy)\n",
            "\t6.43s\t = Training   runtime\n",
            "\t0.09s\t = Validation runtime\n",
            "Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 622.76s of the 622.74s of remaining time.\n",
            "\t0.7642\t = Validation score   (accuracy)\n",
            "\t1.43s\t = Training   runtime\n",
            "\t0.17s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 621.06s of the 621.04s of remaining time.\n",
            "\t0.7593\t = Validation score   (accuracy)\n",
            "\t1.35s\t = Training   runtime\n",
            "\t0.14s\t = Validation runtime\n",
            "Fitting model: CatBoost_BAG_L2 ... Training model for up to 619.48s of the 619.46s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=8, gpus=0, memory=0.32%)\n",
            "\t0.7812\t = Validation score   (accuracy)\n",
            "\t130.08s\t = Training   runtime\n",
            "\t0.09s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 487.03s of the 487.01s of remaining time.\n",
            "\t0.7658\t = Validation score   (accuracy)\n",
            "\t1.32s\t = Training   runtime\n",
            "\t0.15s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr_BAG_L2 ... Training model for up to 485.47s of the 485.45s of remaining time.\n",
            "\t0.7585\t = Validation score   (accuracy)\n",
            "\t1.32s\t = Training   runtime\n",
            "\t0.15s\t = Validation runtime\n",
            "Fitting model: XGBoost_BAG_L2 ... Training model for up to 483.91s of the 483.89s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=8, gpus=0, memory=0.33%)\n",
            "\t0.7658\t = Validation score   (accuracy)\n",
            "\t1127.02s\t = Training   runtime\n",
            "\t0.16s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the -645.53s of remaining time.\n",
            "\tEnsemble Weights: {'LightGBMXT_BAG_L2': 1.0}\n",
            "\t0.7893\t = Validation score   (accuracy)\n",
            "\t0.39s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 1526.47s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 161.4 rows/s (155 batch size)\n",
            "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
            "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
            "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
            "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
            "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: NeuralNetFastAI_BAG_L1_FULL ...\n",
            "\tStopping at the best epoch learned earlier - 17.\n",
            "\t1.76s\t = Training   runtime\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
            "\t0.49s\t = Training   runtime\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: LightGBM_BAG_L1_FULL ...\n",
            "\t-0.17s\t = Training   runtime\n",
            "Fitting model: RandomForestGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\t1.38s\t = Training   runtime\n",
            "\t0.14s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\t1.36s\t = Training   runtime\n",
            "\t0.17s\t = Validation runtime\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: CatBoost_BAG_L1_FULL ...\n",
            "\t2.43s\t = Training   runtime\n",
            "Fitting model: ExtraTreesGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\t1.31s\t = Training   runtime\n",
            "\t0.15s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\t1.33s\t = Training   runtime\n",
            "\t0.14s\t = Validation runtime\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: XGBoost_BAG_L1_FULL ...\n",
            "\t0.24s\t = Training   runtime\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: NeuralNetTorch_BAG_L1_FULL ...\n",
            "\t3.49s\t = Training   runtime\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: LightGBMLarge_BAG_L1_FULL ...\n",
            "\t1.08s\t = Training   runtime\n",
            "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
            "\tEnsemble Weights: {'LightGBM_BAG_L1': 0.846, 'CatBoost_BAG_L1': 0.077, 'XGBoost_BAG_L1': 0.077}\n",
            "\t0.17s\t = Training   runtime\n",
            "Fitting 1 L2 models ...\n",
            "Fitting model: NeuralNetFastAI_BAG_L2_FULL ...\n",
            "\tStopping at the best epoch learned earlier - 8.\n",
            "\t0.77s\t = Training   runtime\n",
            "Fitting 1 L2 models ...\n",
            "Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
            "\t0.8s\t = Training   runtime\n",
            "Fitting 1 L2 models ...\n",
            "Fitting model: LightGBM_BAG_L2_FULL ...\n",
            "\t0.77s\t = Training   runtime\n",
            "Fitting model: RandomForestGini_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
            "\t1.43s\t = Training   runtime\n",
            "\t0.17s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
            "\t1.35s\t = Training   runtime\n",
            "\t0.14s\t = Validation runtime\n",
            "Fitting 1 L2 models ...\n",
            "Fitting model: CatBoost_BAG_L2_FULL ...\n",
            "\t3.97s\t = Training   runtime\n",
            "Fitting model: ExtraTreesGini_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
            "\t1.32s\t = Training   runtime\n",
            "\t0.15s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
            "\t1.32s\t = Training   runtime\n",
            "\t0.15s\t = Validation runtime\n",
            "Fitting 1 L2 models ...\n",
            "Fitting model: XGBoost_BAG_L2_FULL ...\n",
            "\t1.0s\t = Training   runtime\n",
            "Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
            "\tEnsemble Weights: {'LightGBMXT_BAG_L2': 1.0}\n",
            "\t0.39s\t = Training   runtime\n",
            "Updated best model to \"LightGBMXT_BAG_L2_FULL\" (Previously \"WeightedEnsemble_L3\"). AutoGluon will default to using \"LightGBMXT_BAG_L2_FULL\" for predict() and predict_proba().\n",
            "Refit complete, total runtime = 20.75s ... Best model: \"LightGBMXT_BAG_L2_FULL\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels-predictRanking\")\n"
          ]
        }
      ],
      "source": [
        "time_limit = 1200  # for quick demonstration only, you should set this to longest time you are willing to wait (in seconds)\n",
        "\n",
        "save_path = \"agModels-predictRanking\"  # specifies folder to store trained models\n",
        "predictor = TabularPredictor(\n",
        "    label=label, path=save_path, problem_type=\"multiclass\"\n",
        ").fit(train_data, presets=\"good_quality\", num_gpus=1, time_limit=time_limit)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "Q8cr2ugjndvk",
        "outputId": "5e232f84-22df-4ae0-e2b0-ab5135ccb5ca"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>inde</th>\n",
              "      <th>ano</th>\n",
              "      <th>pedra</th>\n",
              "      <th>idade</th>\n",
              "      <th>fase</th>\n",
              "      <th>ipv</th>\n",
              "      <th>diff_fase</th>\n",
              "      <th>ipp</th>\n",
              "      <th>ieg</th>\n",
              "      <th>ian</th>\n",
              "      <th>ponto_virada</th>\n",
              "      <th>ida</th>\n",
              "      <th>ips</th>\n",
              "      <th>na_fase</th>\n",
              "      <th>iaa</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>983</th>\n",
              "      <td>7.549000</td>\n",
              "      <td>t1</td>\n",
              "      <td>Ametista</td>\n",
              "      <td>11</td>\n",
              "      <td>2</td>\n",
              "      <td>9.200000</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>7.900000</td>\n",
              "      <td>7.50</td>\n",
              "      <td>2.5</td>\n",
              "      <td>Sim</td>\n",
              "      <td>7.600000</td>\n",
              "      <td>7.500</td>\n",
              "      <td>False</td>\n",
              "      <td>9.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1469</th>\n",
              "      <td>7.006000</td>\n",
              "      <td>t1</td>\n",
              "      <td>Ametista</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>6.600000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.600000</td>\n",
              "      <td>8.30</td>\n",
              "      <td>10.0</td>\n",
              "      <td>Não</td>\n",
              "      <td>4.400000</td>\n",
              "      <td>7.500</td>\n",
              "      <td>True</td>\n",
              "      <td>7.40000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>721</th>\n",
              "      <td>8.881000</td>\n",
              "      <td>t1</td>\n",
              "      <td>Topázio</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>8.900000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.800000</td>\n",
              "      <td>9.60</td>\n",
              "      <td>10.0</td>\n",
              "      <td>Não</td>\n",
              "      <td>7.800000</td>\n",
              "      <td>7.500</td>\n",
              "      <td>True</td>\n",
              "      <td>10.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>713</th>\n",
              "      <td>6.519446</td>\n",
              "      <td>t0</td>\n",
              "      <td>Ágata</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>8.055553</td>\n",
              "      <td>-4.0</td>\n",
              "      <td>5.208333</td>\n",
              "      <td>8.00</td>\n",
              "      <td>2.5</td>\n",
              "      <td>Não</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>4.375</td>\n",
              "      <td>False</td>\n",
              "      <td>9.00002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>6.684723</td>\n",
              "      <td>t2</td>\n",
              "      <td>Ágata</td>\n",
              "      <td>15</td>\n",
              "      <td>4</td>\n",
              "      <td>7.416667</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>7.500000</td>\n",
              "      <td>6.25</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Não</td>\n",
              "      <td>6.111111</td>\n",
              "      <td>6.875</td>\n",
              "      <td>False</td>\n",
              "      <td>7.91667</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          inde ano     pedra  idade fase       ipv  diff_fase       ipp   ieg  \\\n",
              "983   7.549000  t1  Ametista     11    2  9.200000       -3.0  7.900000  7.50   \n",
              "1469  7.006000  t1  Ametista      8    0  6.600000        0.0  6.600000  8.30   \n",
              "721   8.881000  t1   Topázio      9    1  8.900000        0.0  8.800000  9.60   \n",
              "713   6.519446  t0     Ágata     15    1  8.055553       -4.0  5.208333  8.00   \n",
              "85    6.684723  t2     Ágata     15    4  7.416667       -1.0  7.500000  6.25   \n",
              "\n",
              "       ian ponto_virada       ida    ips  na_fase       iaa  \n",
              "983    2.5          Sim  7.600000  7.500    False   9.00000  \n",
              "1469  10.0          Não  4.400000  7.500     True   7.40000  \n",
              "721   10.0          Não  7.800000  7.500     True  10.00000  \n",
              "713    2.5          Não  6.000000  4.375    False   9.00002  \n",
              "85     5.0          Não  6.111111  6.875    False   7.91667  "
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_test = test_data[label]  # values to predict\n",
        "test_data_nolab = X_test  # delete label column to prove we're not cheating\n",
        "test_data_nolab.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Olz-RH4np4l",
        "outputId": "4c672327-15fa-4950-f99b-6b69e0b8bb58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predictions:  \n",
            " 983     0.0\n",
            "1469    1.0\n",
            "721     0.0\n",
            "713     3.0\n",
            "85      2.0\n",
            "       ... \n",
            "540     3.0\n",
            "333     0.0\n",
            "1424    2.0\n",
            "1065    1.0\n",
            "879     2.0\n",
            "Name: cg_cat, Length: 412, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "predictor = TabularPredictor.load(\n",
        "    save_path\n",
        ")  # unnecessary, just demonstrates how to load previously-trained predictor from file\n",
        "\n",
        "y_pred = predictor.predict(test_data_nolab)\n",
        "print(\"Predictions:  \\n\", y_pred)\n",
        "perf = predictor.evaluate_predictions(\n",
        "    y_true=y_test, y_pred=y_pred, auxiliary_metrics=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCLg72fvnyyq",
        "outputId": "99a4dbcb-6b58-4f23-d31c-ccbe7894e4d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'accuracy': 0.7427184466019418,\n",
              " 'balanced_accuracy': 0.7423823950275008,\n",
              " 'mcc': 0.6569685130866051}"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "perf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "VOfUasbPn2PN",
        "outputId": "00519b12-75bc-48bd-a513-41acacf180bd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>score_test</th>\n",
              "      <th>score_val</th>\n",
              "      <th>eval_metric</th>\n",
              "      <th>pred_time_test</th>\n",
              "      <th>pred_time_val</th>\n",
              "      <th>fit_time</th>\n",
              "      <th>pred_time_test_marginal</th>\n",
              "      <th>pred_time_val_marginal</th>\n",
              "      <th>fit_time_marginal</th>\n",
              "      <th>stack_level</th>\n",
              "      <th>can_infer</th>\n",
              "      <th>fit_order</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CatBoost_BAG_L2_FULL</td>\n",
              "      <td>0.764563</td>\n",
              "      <td>NaN</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>1.089985</td>\n",
              "      <td>NaN</td>\n",
              "      <td>18.672310</td>\n",
              "      <td>0.013913</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.970665</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RandomForestEntr_BAG_L2_FULL</td>\n",
              "      <td>0.762136</td>\n",
              "      <td>NaN</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>1.290425</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16.055262</td>\n",
              "      <td>0.214353</td>\n",
              "      <td>0.142513</td>\n",
              "      <td>1.353617</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ExtraTreesGini_BAG_L2_FULL</td>\n",
              "      <td>0.757282</td>\n",
              "      <td>NaN</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>1.288022</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16.019050</td>\n",
              "      <td>0.211950</td>\n",
              "      <td>0.147853</td>\n",
              "      <td>1.317405</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RandomForestGini_BAG_L2_FULL</td>\n",
              "      <td>0.752427</td>\n",
              "      <td>NaN</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>0.708862</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16.134337</td>\n",
              "      <td>-0.367210</td>\n",
              "      <td>0.167199</td>\n",
              "      <td>1.432692</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NeuralNetFastAI_BAG_L2_FULL</td>\n",
              "      <td>0.752427</td>\n",
              "      <td>NaN</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>1.112448</td>\n",
              "      <td>NaN</td>\n",
              "      <td>15.469522</td>\n",
              "      <td>0.036376</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.767878</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>ExtraTreesEntr_BAG_L2_FULL</td>\n",
              "      <td>0.752427</td>\n",
              "      <td>NaN</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>1.290262</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16.021722</td>\n",
              "      <td>0.214190</td>\n",
              "      <td>0.147089</td>\n",
              "      <td>1.320077</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>WeightedEnsemble_L2_FULL</td>\n",
              "      <td>0.745146</td>\n",
              "      <td>NaN</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>0.064400</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.669059</td>\n",
              "      <td>0.004167</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.172824</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>XGBoost_BAG_L1_FULL</td>\n",
              "      <td>0.742718</td>\n",
              "      <td>NaN</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>0.018676</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.235505</td>\n",
              "      <td>0.018676</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.235505</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>LightGBMXT_BAG_L2_FULL</td>\n",
              "      <td>0.742718</td>\n",
              "      <td>NaN</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>1.138442</td>\n",
              "      <td>NaN</td>\n",
              "      <td>15.498967</td>\n",
              "      <td>0.062370</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.797323</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>WeightedEnsemble_L3_FULL</td>\n",
              "      <td>0.742718</td>\n",
              "      <td>NaN</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>1.140717</td>\n",
              "      <td>NaN</td>\n",
              "      <td>15.887399</td>\n",
              "      <td>0.002275</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.388432</td>\n",
              "      <td>3</td>\n",
              "      <td>True</td>\n",
              "      <td>44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>LightGBM_BAG_L1_FULL</td>\n",
              "      <td>0.737864</td>\n",
              "      <td>NaN</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>0.032027</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.172124</td>\n",
              "      <td>0.032027</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.172124</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>LightGBMLarge_BAG_L1_FULL</td>\n",
              "      <td>0.735437</td>\n",
              "      <td>NaN</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>0.052174</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.082296</td>\n",
              "      <td>0.052174</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.082296</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>RandomForestGini_BAG_L1_FULL</td>\n",
              "      <td>0.735437</td>\n",
              "      <td>NaN</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>0.209918</td>\n",
              "      <td>0.140728</td>\n",
              "      <td>1.376203</td>\n",
              "      <td>0.209918</td>\n",
              "      <td>0.140728</td>\n",
              "      <td>1.376203</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>RandomForestGini_BAG_L1</td>\n",
              "      <td>0.735437</td>\n",
              "      <td>0.731767</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>0.213245</td>\n",
              "      <td>0.140728</td>\n",
              "      <td>1.376203</td>\n",
              "      <td>0.213245</td>\n",
              "      <td>0.140728</td>\n",
              "      <td>1.376203</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>LightGBM_BAG_L2_FULL</td>\n",
              "      <td>0.733010</td>\n",
              "      <td>NaN</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>1.104728</td>\n",
              "      <td>NaN</td>\n",
              "      <td>15.473787</td>\n",
              "      <td>0.028656</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.772142</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>CatBoost_BAG_L1_FULL</td>\n",
              "      <td>0.728155</td>\n",
              "      <td>NaN</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>0.009530</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.432855</td>\n",
              "      <td>0.009530</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.432855</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>XGBoost_BAG_L2_FULL</td>\n",
              "      <td>0.725728</td>\n",
              "      <td>NaN</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>1.096299</td>\n",
              "      <td>NaN</td>\n",
              "      <td>15.696752</td>\n",
              "      <td>0.020227</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.995107</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>RandomForestEntr_BAG_L1_FULL</td>\n",
              "      <td>0.723301</td>\n",
              "      <td>NaN</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>0.204627</td>\n",
              "      <td>0.166187</td>\n",
              "      <td>1.360111</td>\n",
              "      <td>0.204627</td>\n",
              "      <td>0.166187</td>\n",
              "      <td>1.360111</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>RandomForestEntr_BAG_L1</td>\n",
              "      <td>0.723301</td>\n",
              "      <td>0.731767</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>0.211049</td>\n",
              "      <td>0.166187</td>\n",
              "      <td>1.360111</td>\n",
              "      <td>0.211049</td>\n",
              "      <td>0.166187</td>\n",
              "      <td>1.360111</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>LightGBMXT_BAG_L1_FULL</td>\n",
              "      <td>0.716019</td>\n",
              "      <td>NaN</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>0.052572</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.493680</td>\n",
              "      <td>0.052572</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.493680</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>NeuralNetFastAI_BAG_L1_FULL</td>\n",
              "      <td>0.686893</td>\n",
              "      <td>NaN</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>0.033962</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.764189</td>\n",
              "      <td>0.033962</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.764189</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>ExtraTreesEntr_BAG_L1_FULL</td>\n",
              "      <td>0.684466</td>\n",
              "      <td>NaN</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>0.215987</td>\n",
              "      <td>0.143027</td>\n",
              "      <td>1.333199</td>\n",
              "      <td>0.215987</td>\n",
              "      <td>0.143027</td>\n",
              "      <td>1.333199</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>ExtraTreesEntr_BAG_L1</td>\n",
              "      <td>0.684466</td>\n",
              "      <td>0.696921</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>0.216695</td>\n",
              "      <td>0.143027</td>\n",
              "      <td>1.333199</td>\n",
              "      <td>0.216695</td>\n",
              "      <td>0.143027</td>\n",
              "      <td>1.333199</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>ExtraTreesGini_BAG_L1_FULL</td>\n",
              "      <td>0.674757</td>\n",
              "      <td>NaN</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>0.216132</td>\n",
              "      <td>0.145655</td>\n",
              "      <td>1.305529</td>\n",
              "      <td>0.216132</td>\n",
              "      <td>0.145655</td>\n",
              "      <td>1.305529</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>ExtraTreesGini_BAG_L1</td>\n",
              "      <td>0.674757</td>\n",
              "      <td>0.696921</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>0.216393</td>\n",
              "      <td>0.145655</td>\n",
              "      <td>1.305529</td>\n",
              "      <td>0.216393</td>\n",
              "      <td>0.145655</td>\n",
              "      <td>1.305529</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>NeuralNetTorch_BAG_L1_FULL</td>\n",
              "      <td>0.655340</td>\n",
              "      <td>NaN</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>0.030467</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.490202</td>\n",
              "      <td>0.030467</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.490202</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>LightGBMXT_BAG_L2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.789303</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.480766</td>\n",
              "      <td>181.264875</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.084925</td>\n",
              "      <td>4.350668</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>WeightedEnsemble_L3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.789303</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.482740</td>\n",
              "      <td>181.653307</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.001974</td>\n",
              "      <td>0.388432</td>\n",
              "      <td>3</td>\n",
              "      <td>False</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>CatBoost_BAG_L2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.781199</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.483884</td>\n",
              "      <td>306.997560</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.088043</td>\n",
              "      <td>130.083353</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>LightGBM_BAG_L2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.780389</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.483779</td>\n",
              "      <td>183.346845</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.087939</td>\n",
              "      <td>6.432638</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>WeightedEnsemble_L2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.773906</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.215887</td>\n",
              "      <td>61.813735</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.001226</td>\n",
              "      <td>0.172824</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>NeuralNetFastAI_BAG_L2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.773906</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.616688</td>\n",
              "      <td>218.839254</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.220848</td>\n",
              "      <td>41.925047</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>LightGBM_BAG_L1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.770665</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.068880</td>\n",
              "      <td>3.082508</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.068880</td>\n",
              "      <td>3.082508</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>CatBoost_BAG_L1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.765802</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.048637</td>\n",
              "      <td>38.293540</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.048637</td>\n",
              "      <td>38.293540</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>ExtraTreesGini_BAG_L2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.765802</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.543694</td>\n",
              "      <td>178.231612</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.147853</td>\n",
              "      <td>1.317405</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>XGBoost_BAG_L2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.765802</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.552287</td>\n",
              "      <td>1303.937207</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.156446</td>\n",
              "      <td>1127.023000</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>RandomForestGini_BAG_L2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.764182</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.563040</td>\n",
              "      <td>178.346899</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.167199</td>\n",
              "      <td>1.432692</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>RandomForestEntr_BAG_L2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.759319</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.538353</td>\n",
              "      <td>178.267824</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.142513</td>\n",
              "      <td>1.353617</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>ExtraTreesEntr_BAG_L2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.758509</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.542930</td>\n",
              "      <td>178.234284</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.147089</td>\n",
              "      <td>1.320077</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>XGBoost_BAG_L1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.756888</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.097143</td>\n",
              "      <td>20.264863</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.097143</td>\n",
              "      <td>20.264863</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>LightGBMLarge_BAG_L1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.748784</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.086132</td>\n",
              "      <td>5.087298</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.086132</td>\n",
              "      <td>5.087298</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>LightGBMXT_BAG_L1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.744733</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.097136</td>\n",
              "      <td>2.084573</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.097136</td>\n",
              "      <td>2.084573</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>NeuralNetTorch_BAG_L1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.724473</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.169413</td>\n",
              "      <td>60.117285</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.169413</td>\n",
              "      <td>60.117285</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>NeuralNetFastAI_BAG_L1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.723663</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.232902</td>\n",
              "      <td>42.609098</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.232902</td>\n",
              "      <td>42.609098</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           model  score_test  score_val eval_metric  \\\n",
              "0           CatBoost_BAG_L2_FULL    0.764563        NaN    accuracy   \n",
              "1   RandomForestEntr_BAG_L2_FULL    0.762136        NaN    accuracy   \n",
              "2     ExtraTreesGini_BAG_L2_FULL    0.757282        NaN    accuracy   \n",
              "3   RandomForestGini_BAG_L2_FULL    0.752427        NaN    accuracy   \n",
              "4    NeuralNetFastAI_BAG_L2_FULL    0.752427        NaN    accuracy   \n",
              "5     ExtraTreesEntr_BAG_L2_FULL    0.752427        NaN    accuracy   \n",
              "6       WeightedEnsemble_L2_FULL    0.745146        NaN    accuracy   \n",
              "7            XGBoost_BAG_L1_FULL    0.742718        NaN    accuracy   \n",
              "8         LightGBMXT_BAG_L2_FULL    0.742718        NaN    accuracy   \n",
              "9       WeightedEnsemble_L3_FULL    0.742718        NaN    accuracy   \n",
              "10          LightGBM_BAG_L1_FULL    0.737864        NaN    accuracy   \n",
              "11     LightGBMLarge_BAG_L1_FULL    0.735437        NaN    accuracy   \n",
              "12  RandomForestGini_BAG_L1_FULL    0.735437        NaN    accuracy   \n",
              "13       RandomForestGini_BAG_L1    0.735437   0.731767    accuracy   \n",
              "14          LightGBM_BAG_L2_FULL    0.733010        NaN    accuracy   \n",
              "15          CatBoost_BAG_L1_FULL    0.728155        NaN    accuracy   \n",
              "16           XGBoost_BAG_L2_FULL    0.725728        NaN    accuracy   \n",
              "17  RandomForestEntr_BAG_L1_FULL    0.723301        NaN    accuracy   \n",
              "18       RandomForestEntr_BAG_L1    0.723301   0.731767    accuracy   \n",
              "19        LightGBMXT_BAG_L1_FULL    0.716019        NaN    accuracy   \n",
              "20   NeuralNetFastAI_BAG_L1_FULL    0.686893        NaN    accuracy   \n",
              "21    ExtraTreesEntr_BAG_L1_FULL    0.684466        NaN    accuracy   \n",
              "22         ExtraTreesEntr_BAG_L1    0.684466   0.696921    accuracy   \n",
              "23    ExtraTreesGini_BAG_L1_FULL    0.674757        NaN    accuracy   \n",
              "24         ExtraTreesGini_BAG_L1    0.674757   0.696921    accuracy   \n",
              "25    NeuralNetTorch_BAG_L1_FULL    0.655340        NaN    accuracy   \n",
              "26             LightGBMXT_BAG_L2         NaN   0.789303    accuracy   \n",
              "27           WeightedEnsemble_L3         NaN   0.789303    accuracy   \n",
              "28               CatBoost_BAG_L2         NaN   0.781199    accuracy   \n",
              "29               LightGBM_BAG_L2         NaN   0.780389    accuracy   \n",
              "30           WeightedEnsemble_L2         NaN   0.773906    accuracy   \n",
              "31        NeuralNetFastAI_BAG_L2         NaN   0.773906    accuracy   \n",
              "32               LightGBM_BAG_L1         NaN   0.770665    accuracy   \n",
              "33               CatBoost_BAG_L1         NaN   0.765802    accuracy   \n",
              "34         ExtraTreesGini_BAG_L2         NaN   0.765802    accuracy   \n",
              "35                XGBoost_BAG_L2         NaN   0.765802    accuracy   \n",
              "36       RandomForestGini_BAG_L2         NaN   0.764182    accuracy   \n",
              "37       RandomForestEntr_BAG_L2         NaN   0.759319    accuracy   \n",
              "38         ExtraTreesEntr_BAG_L2         NaN   0.758509    accuracy   \n",
              "39                XGBoost_BAG_L1         NaN   0.756888    accuracy   \n",
              "40          LightGBMLarge_BAG_L1         NaN   0.748784    accuracy   \n",
              "41             LightGBMXT_BAG_L1         NaN   0.744733    accuracy   \n",
              "42         NeuralNetTorch_BAG_L1         NaN   0.724473    accuracy   \n",
              "43        NeuralNetFastAI_BAG_L1         NaN   0.723663    accuracy   \n",
              "\n",
              "    pred_time_test  pred_time_val     fit_time  pred_time_test_marginal  \\\n",
              "0         1.089985            NaN    18.672310                 0.013913   \n",
              "1         1.290425            NaN    16.055262                 0.214353   \n",
              "2         1.288022            NaN    16.019050                 0.211950   \n",
              "3         0.708862            NaN    16.134337                -0.367210   \n",
              "4         1.112448            NaN    15.469522                 0.036376   \n",
              "5         1.290262            NaN    16.021722                 0.214190   \n",
              "6         0.064400            NaN     2.669059                 0.004167   \n",
              "7         0.018676            NaN     0.235505                 0.018676   \n",
              "8         1.138442            NaN    15.498967                 0.062370   \n",
              "9         1.140717            NaN    15.887399                 0.002275   \n",
              "10        0.032027            NaN    -0.172124                 0.032027   \n",
              "11        0.052174            NaN     1.082296                 0.052174   \n",
              "12        0.209918       0.140728     1.376203                 0.209918   \n",
              "13        0.213245       0.140728     1.376203                 0.213245   \n",
              "14        1.104728            NaN    15.473787                 0.028656   \n",
              "15        0.009530            NaN     2.432855                 0.009530   \n",
              "16        1.096299            NaN    15.696752                 0.020227   \n",
              "17        0.204627       0.166187     1.360111                 0.204627   \n",
              "18        0.211049       0.166187     1.360111                 0.211049   \n",
              "19        0.052572            NaN     0.493680                 0.052572   \n",
              "20        0.033962            NaN     1.764189                 0.033962   \n",
              "21        0.215987       0.143027     1.333199                 0.215987   \n",
              "22        0.216695       0.143027     1.333199                 0.216695   \n",
              "23        0.216132       0.145655     1.305529                 0.216132   \n",
              "24        0.216393       0.145655     1.305529                 0.216393   \n",
              "25        0.030467            NaN     3.490202                 0.030467   \n",
              "26             NaN       1.480766   181.264875                      NaN   \n",
              "27             NaN       1.482740   181.653307                      NaN   \n",
              "28             NaN       1.483884   306.997560                      NaN   \n",
              "29             NaN       1.483779   183.346845                      NaN   \n",
              "30             NaN       0.215887    61.813735                      NaN   \n",
              "31             NaN       1.616688   218.839254                      NaN   \n",
              "32             NaN       0.068880     3.082508                      NaN   \n",
              "33             NaN       0.048637    38.293540                      NaN   \n",
              "34             NaN       1.543694   178.231612                      NaN   \n",
              "35             NaN       1.552287  1303.937207                      NaN   \n",
              "36             NaN       1.563040   178.346899                      NaN   \n",
              "37             NaN       1.538353   178.267824                      NaN   \n",
              "38             NaN       1.542930   178.234284                      NaN   \n",
              "39             NaN       0.097143    20.264863                      NaN   \n",
              "40             NaN       0.086132     5.087298                      NaN   \n",
              "41             NaN       0.097136     2.084573                      NaN   \n",
              "42             NaN       0.169413    60.117285                      NaN   \n",
              "43             NaN       0.232902    42.609098                      NaN   \n",
              "\n",
              "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
              "0                      NaN           3.970665            2       True   \n",
              "1                 0.142513           1.353617            2       True   \n",
              "2                 0.147853           1.317405            2       True   \n",
              "3                 0.167199           1.432692            2       True   \n",
              "4                      NaN           0.767878            2       True   \n",
              "5                 0.147089           1.320077            2       True   \n",
              "6                      NaN           0.172824            2       True   \n",
              "7                      NaN           0.235505            1       True   \n",
              "8                      NaN           0.797323            2       True   \n",
              "9                      NaN           0.388432            3       True   \n",
              "10                     NaN          -0.172124            1       True   \n",
              "11                     NaN           1.082296            1       True   \n",
              "12                0.140728           1.376203            1       True   \n",
              "13                0.140728           1.376203            1       True   \n",
              "14                     NaN           0.772142            2       True   \n",
              "15                     NaN           2.432855            1       True   \n",
              "16                     NaN           0.995107            2       True   \n",
              "17                0.166187           1.360111            1       True   \n",
              "18                0.166187           1.360111            1       True   \n",
              "19                     NaN           0.493680            1       True   \n",
              "20                     NaN           1.764189            1       True   \n",
              "21                0.143027           1.333199            1       True   \n",
              "22                0.143027           1.333199            1       True   \n",
              "23                0.145655           1.305529            1       True   \n",
              "24                0.145655           1.305529            1       True   \n",
              "25                     NaN           3.490202            1       True   \n",
              "26                0.084925           4.350668            2      False   \n",
              "27                0.001974           0.388432            3      False   \n",
              "28                0.088043         130.083353            2      False   \n",
              "29                0.087939           6.432638            2      False   \n",
              "30                0.001226           0.172824            2      False   \n",
              "31                0.220848          41.925047            2      False   \n",
              "32                0.068880           3.082508            1      False   \n",
              "33                0.048637          38.293540            1      False   \n",
              "34                0.147853           1.317405            2      False   \n",
              "35                0.156446        1127.023000            2      False   \n",
              "36                0.167199           1.432692            2      False   \n",
              "37                0.142513           1.353617            2      False   \n",
              "38                0.147089           1.320077            2      False   \n",
              "39                0.097143          20.264863            1      False   \n",
              "40                0.086132           5.087298            1      False   \n",
              "41                0.097136           2.084573            1      False   \n",
              "42                0.169413          60.117285            1      False   \n",
              "43                0.232902          42.609098            1      False   \n",
              "\n",
              "    fit_order  \n",
              "0          40  \n",
              "1          39  \n",
              "2          41  \n",
              "3          38  \n",
              "4          35  \n",
              "5          42  \n",
              "6          34  \n",
              "7          31  \n",
              "8          36  \n",
              "9          44  \n",
              "10         25  \n",
              "11         33  \n",
              "12         26  \n",
              "13          4  \n",
              "14         37  \n",
              "15         28  \n",
              "16         43  \n",
              "17         27  \n",
              "18          5  \n",
              "19         24  \n",
              "20         23  \n",
              "21         30  \n",
              "22          8  \n",
              "23         29  \n",
              "24          7  \n",
              "25         32  \n",
              "26         14  \n",
              "27         22  \n",
              "28         18  \n",
              "29         15  \n",
              "30         12  \n",
              "31         13  \n",
              "32          3  \n",
              "33          6  \n",
              "34         19  \n",
              "35         21  \n",
              "36         16  \n",
              "37         17  \n",
              "38         20  \n",
              "39          9  \n",
              "40         11  \n",
              "41          2  \n",
              "42         10  \n",
              "43          1  "
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictor.leaderboard(test_data, silent=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMekmBlissfx",
        "outputId": "3f99e95f-d777-4740-8dd4-2bb34ad2fbac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "*** Summary of fit() ***\n",
            "Estimated performance of each model:\n",
            "                           model  score_val eval_metric  pred_time_val     fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0              LightGBMXT_BAG_L2   0.789303    accuracy       1.480766   181.264875                0.084925           4.350668            2      False         14\n",
            "1            WeightedEnsemble_L3   0.789303    accuracy       1.482740   181.653307                0.001974           0.388432            3      False         22\n",
            "2                CatBoost_BAG_L2   0.781199    accuracy       1.483884   306.997560                0.088043         130.083353            2      False         18\n",
            "3                LightGBM_BAG_L2   0.780389    accuracy       1.483779   183.346845                0.087939           6.432638            2      False         15\n",
            "4            WeightedEnsemble_L2   0.773906    accuracy       0.215887    61.813735                0.001226           0.172824            2      False         12\n",
            "5         NeuralNetFastAI_BAG_L2   0.773906    accuracy       1.616688   218.839254                0.220848          41.925047            2      False         13\n",
            "6                LightGBM_BAG_L1   0.770665    accuracy       0.068880     3.082508                0.068880           3.082508            1      False          3\n",
            "7                CatBoost_BAG_L1   0.765802    accuracy       0.048637    38.293540                0.048637          38.293540            1      False          6\n",
            "8          ExtraTreesGini_BAG_L2   0.765802    accuracy       1.543694   178.231612                0.147853           1.317405            2      False         19\n",
            "9                 XGBoost_BAG_L2   0.765802    accuracy       1.552287  1303.937207                0.156446        1127.023000            2      False         21\n",
            "10       RandomForestGini_BAG_L2   0.764182    accuracy       1.563040   178.346899                0.167199           1.432692            2      False         16\n",
            "11       RandomForestEntr_BAG_L2   0.759319    accuracy       1.538353   178.267824                0.142513           1.353617            2      False         17\n",
            "12         ExtraTreesEntr_BAG_L2   0.758509    accuracy       1.542930   178.234284                0.147089           1.320077            2      False         20\n",
            "13                XGBoost_BAG_L1   0.756888    accuracy       0.097143    20.264863                0.097143          20.264863            1      False          9\n",
            "14          LightGBMLarge_BAG_L1   0.748784    accuracy       0.086132     5.087298                0.086132           5.087298            1      False         11\n",
            "15             LightGBMXT_BAG_L1   0.744733    accuracy       0.097136     2.084573                0.097136           2.084573            1      False          2\n",
            "16       RandomForestGini_BAG_L1   0.731767    accuracy       0.140728     1.376203                0.140728           1.376203            1       True          4\n",
            "17       RandomForestEntr_BAG_L1   0.731767    accuracy       0.166187     1.360111                0.166187           1.360111            1       True          5\n",
            "18         NeuralNetTorch_BAG_L1   0.724473    accuracy       0.169413    60.117285                0.169413          60.117285            1      False         10\n",
            "19        NeuralNetFastAI_BAG_L1   0.723663    accuracy       0.232902    42.609098                0.232902          42.609098            1      False          1\n",
            "20         ExtraTreesEntr_BAG_L1   0.696921    accuracy       0.143027     1.333199                0.143027           1.333199            1       True          8\n",
            "21         ExtraTreesGini_BAG_L1   0.696921    accuracy       0.145655     1.305529                0.145655           1.305529            1       True          7\n",
            "22  RandomForestGini_BAG_L1_FULL        NaN    accuracy       0.140728     1.376203                0.140728           1.376203            1       True         26\n",
            "23    ExtraTreesEntr_BAG_L1_FULL        NaN    accuracy       0.143027     1.333199                0.143027           1.333199            1       True         30\n",
            "24    ExtraTreesGini_BAG_L1_FULL        NaN    accuracy       0.145655     1.305529                0.145655           1.305529            1       True         29\n",
            "25  RandomForestEntr_BAG_L1_FULL        NaN    accuracy       0.166187     1.360111                0.166187           1.360111            1       True         27\n",
            "26           XGBoost_BAG_L2_FULL        NaN    accuracy            NaN    15.696752                     NaN           0.995107            2       True         43\n",
            "27           XGBoost_BAG_L1_FULL        NaN    accuracy            NaN     0.235505                     NaN           0.235505            1       True         31\n",
            "28      WeightedEnsemble_L3_FULL        NaN    accuracy            NaN    15.887399                     NaN           0.388432            3       True         44\n",
            "29      WeightedEnsemble_L2_FULL        NaN    accuracy            NaN     2.669059                     NaN           0.172824            2       True         34\n",
            "30  RandomForestGini_BAG_L2_FULL        NaN    accuracy            NaN    16.134337                0.167199           1.432692            2       True         38\n",
            "31  RandomForestEntr_BAG_L2_FULL        NaN    accuracy            NaN    16.055262                0.142513           1.353617            2       True         39\n",
            "32    NeuralNetTorch_BAG_L1_FULL        NaN    accuracy            NaN     3.490202                     NaN           3.490202            1       True         32\n",
            "33   NeuralNetFastAI_BAG_L2_FULL        NaN    accuracy            NaN    15.469522                     NaN           0.767878            2       True         35\n",
            "34   NeuralNetFastAI_BAG_L1_FULL        NaN    accuracy            NaN     1.764189                     NaN           1.764189            1       True         23\n",
            "35          LightGBM_BAG_L2_FULL        NaN    accuracy            NaN    15.473787                     NaN           0.772142            2       True         37\n",
            "36          LightGBM_BAG_L1_FULL        NaN    accuracy            NaN    -0.172124                     NaN          -0.172124            1       True         25\n",
            "37        LightGBMXT_BAG_L2_FULL        NaN    accuracy            NaN    15.498967                     NaN           0.797323            2       True         36\n",
            "38        LightGBMXT_BAG_L1_FULL        NaN    accuracy            NaN     0.493680                     NaN           0.493680            1       True         24\n",
            "39     LightGBMLarge_BAG_L1_FULL        NaN    accuracy            NaN     1.082296                     NaN           1.082296            1       True         33\n",
            "40    ExtraTreesGini_BAG_L2_FULL        NaN    accuracy            NaN    16.019050                0.147853           1.317405            2       True         41\n",
            "41    ExtraTreesEntr_BAG_L2_FULL        NaN    accuracy            NaN    16.021722                0.147089           1.320077            2       True         42\n",
            "42          CatBoost_BAG_L2_FULL        NaN    accuracy            NaN    18.672310                     NaN           3.970665            2       True         40\n",
            "43          CatBoost_BAG_L1_FULL        NaN    accuracy            NaN     2.432855                     NaN           2.432855            1       True         28\n",
            "Number of models trained: 44\n",
            "Types of models trained:\n",
            "{'WeightedEnsembleModel', 'StackerEnsembleModel_XGBoost', 'StackerEnsembleModel_XT', 'StackerEnsembleModel_CatBoost', 'StackerEnsembleModel_LGB', 'StackerEnsembleModel_TabularNeuralNetTorch', 'StackerEnsembleModel_NNFastAiTabular', 'StackerEnsembleModel_RF'}\n",
            "Bagging used: True  (with 8 folds)\n",
            "Multi-layer stack-ensembling used: True  (with 3 levels)\n",
            "Feature Metadata (Processed):\n",
            "(raw dtype, special dtypes):\n",
            "('category', [])  : 4 | ['ano', 'pedra', 'fase', 'ian']\n",
            "('float', [])     : 8 | ['inde', 'ipv', 'diff_fase', 'ipp', 'ieg', ...]\n",
            "('int', [])       : 1 | ['idade']\n",
            "('int', ['bool']) : 2 | ['ponto_virada', 'na_fase']\n",
            "Plot summary of models saved to file: agModels-predictRankingSummaryOfModels.html\n",
            "*** End of fit() summary ***\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "gio: file:///home/alien-wsl/projects/datathon_app/datathonapp/notebooks/agModels-predictRankingSummaryOfModels.html: Failed to find default application for content type ‘text/html’\n"
          ]
        }
      ],
      "source": [
        "results = predictor.fit_summary(show_plot=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWjyNXy-s1JC",
        "outputId": "0ba1c858-0ce4-4911-fe54-9934b4ef5656"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AutoGluon infers problem type is:  multiclass\n",
            "AutoGluon identified the following types of features:\n",
            "('category', [])  : 4 | ['ano', 'pedra', 'fase', 'ian']\n",
            "('float', [])     : 8 | ['inde', 'ipv', 'diff_fase', 'ipp', 'ieg', ...]\n",
            "('int', [])       : 1 | ['idade']\n",
            "('int', ['bool']) : 2 | ['ponto_virada', 'na_fase']\n"
          ]
        }
      ],
      "source": [
        "print(\"AutoGluon infers problem type is: \", predictor.problem_type)\n",
        "print(\"AutoGluon identified the following types of features:\")\n",
        "print(predictor.feature_metadata)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Computing feature importance via permutation shuffling for 15 features using 412 rows with 5 shuffle sets...\n",
            "\t90.21s\t= Expected runtime (18.04s per shuffle set)\n",
            "\t8.7s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>importance</th>\n",
              "      <th>stddev</th>\n",
              "      <th>p_value</th>\n",
              "      <th>n</th>\n",
              "      <th>p99_high</th>\n",
              "      <th>p99_low</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>inde</th>\n",
              "      <td>0.344660</td>\n",
              "      <td>0.009556</td>\n",
              "      <td>7.083474e-08</td>\n",
              "      <td>5</td>\n",
              "      <td>0.364336</td>\n",
              "      <td>0.324985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ano</th>\n",
              "      <td>0.142233</td>\n",
              "      <td>0.013794</td>\n",
              "      <td>1.048501e-05</td>\n",
              "      <td>5</td>\n",
              "      <td>0.170636</td>\n",
              "      <td>0.113830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ipv</th>\n",
              "      <td>0.023786</td>\n",
              "      <td>0.006044</td>\n",
              "      <td>4.598046e-04</td>\n",
              "      <td>5</td>\n",
              "      <td>0.036230</td>\n",
              "      <td>0.011342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pedra</th>\n",
              "      <td>0.019903</td>\n",
              "      <td>0.014194</td>\n",
              "      <td>1.750213e-02</td>\n",
              "      <td>5</td>\n",
              "      <td>0.049129</td>\n",
              "      <td>-0.009323</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>na_fase</th>\n",
              "      <td>0.017476</td>\n",
              "      <td>0.007362</td>\n",
              "      <td>3.027367e-03</td>\n",
              "      <td>5</td>\n",
              "      <td>0.032634</td>\n",
              "      <td>0.002317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ida</th>\n",
              "      <td>0.009709</td>\n",
              "      <td>0.005149</td>\n",
              "      <td>6.758441e-03</td>\n",
              "      <td>5</td>\n",
              "      <td>0.020310</td>\n",
              "      <td>-0.000893</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ipp</th>\n",
              "      <td>0.008738</td>\n",
              "      <td>0.007977</td>\n",
              "      <td>3.524200e-02</td>\n",
              "      <td>5</td>\n",
              "      <td>0.025162</td>\n",
              "      <td>-0.007686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>idade</th>\n",
              "      <td>0.007282</td>\n",
              "      <td>0.010440</td>\n",
              "      <td>9.693005e-02</td>\n",
              "      <td>5</td>\n",
              "      <td>0.028777</td>\n",
              "      <td>-0.014214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>iaa</th>\n",
              "      <td>0.003398</td>\n",
              "      <td>0.007200</td>\n",
              "      <td>1.754074e-01</td>\n",
              "      <td>5</td>\n",
              "      <td>0.018223</td>\n",
              "      <td>-0.011427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fase</th>\n",
              "      <td>0.002913</td>\n",
              "      <td>0.007940</td>\n",
              "      <td>2.290561e-01</td>\n",
              "      <td>5</td>\n",
              "      <td>0.019260</td>\n",
              "      <td>-0.013435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ieg</th>\n",
              "      <td>0.000971</td>\n",
              "      <td>0.006329</td>\n",
              "      <td>3.744342e-01</td>\n",
              "      <td>5</td>\n",
              "      <td>0.014003</td>\n",
              "      <td>-0.012061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>diff_fase</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.004854</td>\n",
              "      <td>5.000000e-01</td>\n",
              "      <td>5</td>\n",
              "      <td>0.009995</td>\n",
              "      <td>-0.009995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ponto_virada</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.000000e-01</td>\n",
              "      <td>5</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ips</th>\n",
              "      <td>-0.000485</td>\n",
              "      <td>0.003600</td>\n",
              "      <td>6.109752e-01</td>\n",
              "      <td>5</td>\n",
              "      <td>0.006927</td>\n",
              "      <td>-0.007898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ian</th>\n",
              "      <td>-0.000971</td>\n",
              "      <td>0.003681</td>\n",
              "      <td>7.064752e-01</td>\n",
              "      <td>5</td>\n",
              "      <td>0.006608</td>\n",
              "      <td>-0.008550</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              importance    stddev       p_value  n  p99_high   p99_low\n",
              "inde            0.344660  0.009556  7.083474e-08  5  0.364336  0.324985\n",
              "ano             0.142233  0.013794  1.048501e-05  5  0.170636  0.113830\n",
              "ipv             0.023786  0.006044  4.598046e-04  5  0.036230  0.011342\n",
              "pedra           0.019903  0.014194  1.750213e-02  5  0.049129 -0.009323\n",
              "na_fase         0.017476  0.007362  3.027367e-03  5  0.032634  0.002317\n",
              "ida             0.009709  0.005149  6.758441e-03  5  0.020310 -0.000893\n",
              "ipp             0.008738  0.007977  3.524200e-02  5  0.025162 -0.007686\n",
              "idade           0.007282  0.010440  9.693005e-02  5  0.028777 -0.014214\n",
              "iaa             0.003398  0.007200  1.754074e-01  5  0.018223 -0.011427\n",
              "fase            0.002913  0.007940  2.290561e-01  5  0.019260 -0.013435\n",
              "ieg             0.000971  0.006329  3.744342e-01  5  0.014003 -0.012061\n",
              "diff_fase       0.000000  0.004854  5.000000e-01  5  0.009995 -0.009995\n",
              "ponto_virada    0.000000  0.000000  5.000000e-01  5  0.000000  0.000000\n",
              "ips            -0.000485  0.003600  6.109752e-01  5  0.006927 -0.007898\n",
              "ian            -0.000971  0.003681  7.064752e-01  5  0.006608 -0.008550"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictor.feature_importance(test_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics\n",
        "\n",
        "confusion_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
        "\n",
        "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix=confusion_matrix)\n",
        "\n",
        "cm_display.plot()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Computing feature importance via permutation shuffling for 15 features using 412 rows with 5 shuffle sets...\n",
            "\t92.09s\t= Expected runtime (18.42s per shuffle set)\n",
            "\t9.52s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
          ]
        }
      ],
      "source": [
        "features_importance = predictor.feature_importance(test_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['inde',\n",
              " 'ano',\n",
              " 'ipv',\n",
              " 'pedra',\n",
              " 'na_fase',\n",
              " 'ida',\n",
              " 'ipp',\n",
              " 'idade',\n",
              " 'iaa',\n",
              " 'fase',\n",
              " 'ieg']"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "features_importance[features_importance[\"importance\"] > 0].index.to_list()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
